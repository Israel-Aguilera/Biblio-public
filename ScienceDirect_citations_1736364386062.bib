@article{SHINOHARA19892617,
title = {Partition of chlorine compounds between silicate melt and hydrothermal solutions: I. Partition of NaCl-KCl},
journal = {Geochimica et Cosmochimica Acta},
volume = {53},
number = {10},
pages = {2617-2630},
year = {1989},
issn = {0016-7037},
doi = {https://doi.org/10.1016/0016-7037(89)90133-6},
url = {https://www.sciencedirect.com/science/article/pii/0016703789901336},
author = {Hiroshi Shinohara and J.Toshimichi Iiyama and Sadao Matsuo},
abstract = {The partition experiments of NaCl and KCl between silicate melts and aqueous chloride solutions were carried at a temperature of 810°C in the pressure range from 0.6 to 6.0 kb. The chloride concentration in the melt (CClm) was constant in certain ranges of chloride concentration in the aqueous phase (CClaq) at 0.6 and 1.2 kb, which reveals the presence of vapor-liquid immiscibility of the aqueous solution. The variation diagram of CClm and CClaq can be applied to the study of aqueous phases as a new method. The partition ratio of chloride (DClmaq = CClmCClaq) exhibits a strong negative pressure dependence, which is attributed to the large negative partial molar volume of chlorides in the aqueous phase. The distribution coefficient of Na and K (DNaKMAq = (CNamCKm/CNaaqCKaq)) is about 0.75 and has little pressure dependence at pressures higher than 2.2 kb. The distribution coefficient, however, has a positive pressure dependence at pressures lower than 1.2 kb.}
}
@article{VERIKIOS2009418,
title = {Modelling the world wool market: A hybrid approach},
journal = {Economic Modelling},
volume = {26},
number = {2},
pages = {418-431},
year = {2009},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2008.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0264999308001132},
author = {George Verikios},
keywords = {General equilibrium, Multistage production, Partial equilibrium, Tariffs, Wool products},
abstract = {We present a model of the world wool market that merges two modelling traditions: the partial-equilibrium commodity-specific approach and the computable-general-equilibrium approach. The model captures the multistage nature of the wool production system, and the heterogeneous nature of raw wool, processed wool and wool garments. It also captures the important wool producing and consuming regions of the world. We illustrate the utility of the model by estimating the effects of tariff barriers on wool products using partial- and general-equilibrium solutions. We find that either solution generates similar wool industry results, whereas the macroeconomic effects differ significantly with the partial-equilibrium estimates significantly overestimating the benefits of the tariff changes.}
}
@article{GREENBERG197812,
title = {Coherence in Cartesian squares},
journal = {Journal of Algebra},
volume = {50},
number = {1},
pages = {12-25},
year = {1978},
issn = {0021-8693},
doi = {https://doi.org/10.1016/0021-8693(78)90170-9},
url = {https://www.sciencedirect.com/science/article/pii/0021869378901709},
author = {Brian Greenberg},
abstract = {The primary object under consideration is a ring, A, which can be written as a particular type of fiber-product of two other rings. The objective is to ascend properties of the components of A to A itself. The paper concerns itself by and large with the notions of coherence, global dimension, and Tor dimension. Several applications are given.}
}
@article{PAZ1973313,
title = {Integral sequential word functions and growth equivalence of lindenmayer systems},
journal = {Information and Control},
volume = {23},
number = {4},
pages = {313-343},
year = {1973},
issn = {0019-9958},
doi = {https://doi.org/10.1016/S0019-9958(73)80002-6},
url = {https://www.sciencedirect.com/science/article/pii/S0019995873800026},
author = {Azaria Paz and Arto Salomaa},
abstract = {Growth functions of informationless Lindenmayer systems are investigated from the point of view of integral sequential word functions. Algorithms are obtained for the solution of equivalence, minimization and construction problems. It is found out that some of the inclusion relations between language families do not remain valid for the corresponding families of growth functions. Some results concerning context-dependent Lindenmayer systems, as well as growth relations of OL-systems are also obtained.}
}
@article{BELL1997317,
title = {Fuzzy linear regression models for assessing risks of cumulative trauma disorders},
journal = {Fuzzy Sets and Systems},
volume = {92},
number = {3},
pages = {317-340},
year = {1997},
issn = {0165-0114},
doi = {https://doi.org/10.1016/S0165-0114(96)00178-9},
url = {https://www.sciencedirect.com/science/article/pii/S0165011496001789},
author = {Pamela McCauley Bell and Wang Heng},
keywords = {Fuzzy regression analysis, Risk analysis, Cumulative trauma disorders},
abstract = {Cumulative trauma disorders (CTDs) are a major problem in industry and today's office environments, especially for keyboard users. Since comprehensive knowledge about individual or a combination of risk factors contributing to CTDs of the hand and forearm is still lacking, developing methodologies to quantify relationships of risk factors is greatly needed. The purpose of this research was to build fuzzy linear regression models to reveal the relationship of CTD risk factors, to predict the injuries, and to evaluate risk levels of individuals. Twenty-seven keyboard users (twenty-two for model building and five for model validation) and three CTD experts participated in the model building. Four fuzzy models were built corresponding to four risk categories, and a final fuzzy linear model was established using AHP pairwise comparisons. Multicolinearity effects were addressed and a partial standard deviation scaling method was used to eliminate the effects. From a methodological point of view, fuzzy linear regression models provide useful insight into risk factors-CTD relationship.}
}
@article{SUBULAN2015243,
title = {A fuzzy goal programming model to strategic planning problem of a lead/acid battery closed-loop supply chain},
journal = {Journal of Manufacturing Systems},
volume = {37},
pages = {243-264},
year = {2015},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2014.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0278612514001010},
author = {Kemal Subulan and A. Serdar Taşan and Adil Baykasoğlu},
keywords = {Reverse logistics, Closed-loop supply chain network design, Fuzzy goal programming, Battery recycling},
abstract = {Economical, environmental and governmental considerations have forced the lead/acid battery manufacturers to build-up an effective and efficient spent battery collection and recovery systems. The design and implementation of such a collection and recycling system is affected by the distribution, collection and recycling facilities’ location decisions which are strategic and important. A fuzzy multi-objective, multi-echelon and multi-product mixed integer linear programming model with different importance and priorities are developed in this paper. In contrast to the existing multi-objective closed-loop supply chain network design models which are generally cost or profit oriented, a new objective namely “maximization of the collection of returned batteries covered by the opened facilities” is also taken into account. Since the lack of flexibility issues in most of the supply chain planning models, new flexibility objectives such as total recycling and collection volume flexibility are also introduced due to the nature of reverse flows. Fuzzy goal programming model with different importance and priorities is used to solve the developed model. Furthermore, a novel approach for obtaining the desirable achievement degree of each fuzzy goal is proposed based on “weighted geometric mean” for group decision making procedure in which the importance/weights and the index of optimism of each group member are different. The proposed model is applied to an illustrative example based on inspiration from the lead/acid industry in Turkey. Solution of the proposed model is achieved by using ILOG OPL Studio version 6.3. Sensitivity analysis of the proposed model is also presented by considering different scenarios.}
}
@article{DENNER199595,
title = {Application of the background-field method to the electroweak standard model},
journal = {Nuclear Physics B},
volume = {440},
number = {1},
pages = {95-128},
year = {1995},
issn = {0550-3213},
doi = {https://doi.org/10.1016/0550-3213(95)00037-S},
url = {https://www.sciencedirect.com/science/article/pii/055032139500037S},
author = {Ansgar Denner and Georg Weiglein and Stefan Dittmaier},
abstract = {Application of the background-field method yields a gauge-invariant effective action for the electroweak Standard Model, from which simple QED-like Ward identities are derived. As a consequence of these Ward identities, the background-field Green functions are shown to possess very desirable theoretical properties. The renormalization of the Standard Model in the background-field formalism is studied. A consistent on-shell renormalization procedure retaining the full gauge symmetry is presented. The structure of the counterterms is shown to greatly simplify compared to the conventional formalism. A complete list of Feynman rules for the Standard Model in the background-field method is given for arbitrary values of a quantum gauge parameter including all counterterms necessary for one-loop calculations.}
}
@article{GRIFFIN1997429,
title = {PDMA research on new product development practices: Updating trends and benchmarking best practices},
journal = {Journal of Product Innovation Management},
volume = {14},
number = {6},
pages = {429-458},
year = {1997},
issn = {0737-6782},
doi = {https://doi.org/10.1016/S0737-6782(97)00061-1},
url = {https://www.sciencedirect.com/science/article/pii/S0737678297000611},
author = {Abbie Griffin},
abstract = {Product development professionals may have the feeling that yet another buzzword or magic bullet always lurks just around the corner. However, researchers have devoted considerable effort to helping practioners determine which tools, techniques, and methods really do offer a competitive edge. Starting 30 years ago, research efforts have aimed at understanding NPD practices and identifying those which are deemed “best practices.” During the past five years, pursuit of this goal has produced numerous privately available reports and two research efforts sponsored by the PDMA. Abbie Griffin summarizes the results of research efforts undertaken during the past five years and presents findings from the most recent PDMA survey on NPD best practices. This survey, conducted slightly more than five years after PDMA's first best-practices survey, updates trends in processes, organizations, and outcomes for NPD in the U.S., and determines which practices are more commonly associated with firms that are more successful in developing new products. The survey has the following objectives: determining the current status of NPD practices and performance; understanding how product development has changed from five years ago; determining whether NPD practice and performance differ across industry segments; and, investigating process and product development tools that differentiate product development success. The survey findings indicate that NPD processes continue to evolve and become more sophisticated. NPD changes continually on multiple fronts, and firms that fail to keep their NPD practices up to date will suffer an increasingly marked competitive disadvantage. Interestingly, although more than half of the respondents use a cross-functional stage-gate process for NPD, more than onethird of all firms in the study still use no formal process for managing NPD. The findings suggest that firms are not adequately handling the issue of team-based rewards. Project-completion dinners are for the most frequently used NPD reward; they are also the only reward used more by best-practice firms than by the rest of the respondents. The best-practice firms participating in the study do not use financial rewards for NPD. Compared to the other firms in the study, best-practice firms use more multifunctional teams, are more likely to measure NPD processes and outcomes, and expect more from their NPD programs.}
}
@article{FLEETER1981371,
title = {The thermal conductivity of mixtures of nitrogen with four noble gases at room temperature},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {108},
number = {2},
pages = {371-401},
year = {1981},
issn = {0378-4371},
doi = {https://doi.org/10.1016/0378-4371(81)90138-2},
url = {https://www.sciencedirect.com/science/article/pii/0378437181901382},
author = {R.D. Fleeter and J. Kestin and R. Paul and W.A. Wakeham},
abstract = {The paper presents new, absolute measurements of the thermal conductivity of binary mixtures of nitrogen with four monatomic gases, He, Ne, Ar and Kr. The measurements have been performed at 27.5°C as a function of density within the pressure range 0.9–17 MPa. The experimental data have an estimated accuracy of ±0.3%. The experimental results are interpreted with the aid of the kinetic theory expressions of Monchick, Pereira and Mason for the thermal conductivity of polyatomic gas mixtures. These first-order formulae prove to be adequate to describe the experimental data within their uncertainty provided that empirical adjustments are made to the rotational relaxation collision numbers and collision integral ratios occuring in them. It is suggested that more accurate kinetic theory formulae would allow such quantities to be derived with greater precision and physical signifincance.}
}
@article{DEWDNEY1981149,
title = {Oriented two-dimensional circuits},
journal = {Discrete Mathematics},
volume = {33},
number = {2},
pages = {149-162},
year = {1981},
issn = {0012-365X},
doi = {https://doi.org/10.1016/0012-365X(81)90162-X},
url = {https://www.sciencedirect.com/science/article/pii/0012365X8190162X},
author = {A.K. Dewdney and Frank Harary},
abstract = {The natural generalization of a directed graph is an oriented complex, a fundamental concept in algebraic topology. Our study of such complexes follows combinatorial rather than topological lines; when an n-circuit is defined for oriented complexes as a structure achieved by a certain minimization process, we are able to pose a question not easily answered by topological methods, but one directly accessible by elementary combinatorial techniques. Indeed, having asked ourselves what structure such n-circuits possess, we were able to find an answer, at least when n = 2.}
}
@article{GAWRONSKI197617,
title = {Data errors in the computation of free motion},
journal = {Computers & Structures},
volume = {6},
number = {1},
pages = {17-27},
year = {1976},
issn = {0045-7949},
doi = {https://doi.org/10.1016/0045-7949(76)90069-9},
url = {https://www.sciencedirect.com/science/article/pii/0045794976900699},
author = {Wlodzimierz Gawronski},
abstract = {Input data in the computation of free motion (the inertia and stiffness matrices) contain some errors. These errors generate errors of output data (the natural frequency vector, the natural mode vectors). In this paper the relationships between errors of input and output data in the computation of free motion are derived. This analysis is applied to the finite element method. The paper presents program ERROR, which computes the errors of the natural frequencies created by the inertia matrix errors. An example of the influence of the errors of the mass and of the mass moment of inertia on the natural frequencies of a ship hull is presented.}
}
@article{CALANTONE1995235,
title = {Principles of new product management: Exploring the beliefs of product practitioners},
journal = {Journal of Product Innovation Management},
volume = {12},
number = {3},
pages = {235-247},
year = {1995},
issn = {0737-6782},
doi = {https://doi.org/10.1016/0737-6782(95)00020-T},
url = {https://www.sciencedirect.com/science/article/pii/073767829500020T},
author = {Roger J. Calantone and C. Anthony {Di Benedetto} and Ted Haggblom},
abstract = {Conventional wisdom might lead us to conclude that the various disciplines involved in product development and management are often at cross-purposes. For example, practitioners from R&D and engineering have been known to suggest that marketing fails to understand the technical trade-offs involved in product management decisions. Conversely, marketing professionals sometimes complain that their technology-oriented colleagues pursue product development initiatives without adequate market awareness. And practitioners from both sides of this debate have asserted that research on new product development tends to be of the ivory tower variety, with little or no relevance for industry. Are such complaints valid? Perhaps it is time for a reality check. By searching academic literature on product development, Roger J. Calantone, C. Anthony Di Benedetto, and Ted Haggblom have compiled a list of 40 fundamental principles of new product development. This list forms the basis for a survey of new product practitioners from marketing and technical disciplines. The study provides a means for assessing whether practitioners agree with the fundamental principles of new product development that are identified in current academic literature. By obtaining responses from both marketing and technical professionals, the survey also sheds light on whether those two groups hold fundamentally different beliefs regarding new product development. The survey results reveal strong overall agreement among practitioners regarding these fundamental principles of new product management. Managers believe that 80% of the principles are either usually or almost always true. In other words, the survey results support the idea that the academic community is pursuing research issues that are relevant to practitioners, and that they are reaching valid conclusions. There are only a few cases in which the responses from the technical and marketing practitioners differ. Those disagreements probably result from differences in the basic orientations of the two groups. For example, it is not surprising that marketing managers would be more likely to agree that “product users and the marketplace form the most important source for new product ideas,” while technical managers more strongly support the idea that “radically new technologies constitute an important source of new product ideas.” The respondents noted overall disagreement with only a few of the 40 principles. In many of these cases, the academic literature has reached mixed conclusions. In other words, these “principles” might actually be oversimplifications, and further research is probably needed before we can fully understand the issues involved.}
}
@article{NISHIHARA197017,
title = {Electrode kinetics of the acetylacetonate complexes of nickel(II) at the dropping mercury electrode},
journal = {Journal of Electroanalytical Chemistry and Interfacial Electrochemistry},
volume = {28},
number = {1},
pages = {17-32},
year = {1970},
issn = {0022-0728},
doi = {https://doi.org/10.1016/S0022-0728(70)80278-9},
url = {https://www.sciencedirect.com/science/article/pii/S0022072870802789},
author = {Chizuko Nishihara and Hiroaki Matsuda},
abstract = {Summary
The polarographic and chronopotentiometric behavior of nickel(II)-acetyl-acetonate complexes is examined in the pH-range 3.6–9.8. By analysing the dependence of the d.c. polarographic current-voltage curves on the pH-value, the mechanism of the electrode reaction is elucidated and the relevant kinetic parameters, i.e., the transfer coefficients and the electrode reaction rate constants, are evaluated. For the preceding chemical reactions involved, the rate and equilibrium constants are determined by analysing the chronopotentiometric Iτ1/2−I curves. The results obtained are summarized by the reaction scheme illustrated in Fig. 13.}
}
@article{CHOW1992283,
title = {Smoothness of inertial manifolds},
journal = {Journal of Mathematical Analysis and Applications},
volume = {169},
number = {1},
pages = {283-312},
year = {1992},
issn = {0022-247X},
doi = {https://doi.org/10.1016/0022-247X(92)90115-T},
url = {https://www.sciencedirect.com/science/article/pii/0022247X9290115T},
author = {Shui-Nee Chow and Kening Lu and George R Sell}
}
@article{LUCK1992139,
title = {Surgery obstructions of fibre bundles},
journal = {Journal of Pure and Applied Algebra},
volume = {81},
number = {2},
pages = {139-189},
year = {1992},
issn = {0022-4049},
doi = {https://doi.org/10.1016/0022-4049(92)90003-X},
url = {https://www.sciencedirect.com/science/article/pii/002240499290003X},
author = {Wolfgang Lück and Andrew Ranicki},
abstract = {In a previous paper we obtained an algebraic description of the transfer maps p∗:Ln(Z[π1(B)]→Ln+d(Z[π1(e)]) induced in the Wall surgery obstruction groups by a fibration with the fibre F a d-dimensional Poincaré complex. In this paper we define a Π1(B)-equivariant symmetric signature σ∗(F, ω)ϵLd(π1(b), Z) depending only on the fibre transport ω: Π1(B)→[F, F], and prove that the composite p∗p∗:Ln(Z[π1(B)])→Ln+d(Z[π1(b)] is the evaluation σ∗(F, ω)⊗? of the product ⊗:Ld(π1(B), Z⊗Ln(Z[π1(B)])→Ln+d(Z[π1(B)]). This is applied to prove vanishing results for the surgery transfer, such as p∗=0 if F=G is a compact connected d-dimensional Lie group which is not a torus, and is a G-principal bundle. An appendix relates this expression for p∗p∗ to the twisted signature formula of Atiyah, Lusztig and Meyer.}
}
@article{CARRAHER1998211,
title = {Validation of an instrument to measure service-orientation},
journal = {Journal of Quality Management},
volume = {3},
number = {2},
pages = {211-224},
year = {1998},
issn = {1084-8568},
doi = {https://doi.org/10.1016/S1084-8568(99)80114-X},
url = {https://www.sciencedirect.com/science/article/pii/S108485689980114X},
author = {Shawn M. Carraher and Jorge L. Mendoza and M.Ronald Buckley and Lyle F. Schoenfeldt and Charles E. Carraher},
abstract = {Hogan, Hogan, and Busch (1984: 167) define service-orientation as “the disposition to be helpful, thoughtful, considerate, and cooperative.” To measure this construct they developed the Service Orientation Index (SOI), an 87-item true false questionnaire. The purpose of the present study was to test whether or not a biodata inventory could also be used to measure the service-orientation construct. Subjects were given the inventory in order to predict their service-oriented performance in a simulated customer interaction. The service-orientation ratings were consistently highly correlated with three topical scales: “the need to make a good impression,” “sociability,” and “helpfulness.” The correlations of these scales with service-orientation were as high or higher than those generally obtained with the SOI; and thus, it was concluded that service-orientation may effectively be measured by biodata.}
}
@article{COHEN1954501,
title = {The transport properties and equation of state of gaseous mixtures of the helium isotopes},
journal = {Physica},
volume = {20},
number = {1},
pages = {501-515},
year = {1954},
issn = {0031-8914},
doi = {https://doi.org/10.1016/S0031-8914(54)80065-6},
url = {https://www.sciencedirect.com/science/article/pii/S0031891454800656},
author = {E.G.D. Cohen and M.J. Offerhaus and J. {de Boer}},
abstract = {Synopsis
On the basis of the 12-6-Lennard-Jones potential field, used in previous publications to describe the properties of the pure gases 3He and 4He, a quantum mechanical calculation has been made of the properties of gaseous mixtures of 3He and 4He: 1) The self-diffusion coefficient and the mutual diffusion coefficient in first and second approximation; 2) the viscosity and the heat conductivity of mixtures of 3He and 4He; 3) the thermal diffusion ratio kT; 4) the second virial coefficient of mixtures of 3He and 4He. The theoretical data for the viscosity of mixtures of 3He and 4He show a satisfactory agreement with recent measurements made by Van Itterbeek et al. and Becker et al. Measurement of the thermal diffusion would be a very sensitive test of the present calculations.}
}
@article{GOLDMAN1985181,
title = {Gluinonium: The hydrogen atom of supersymmetry},
journal = {Physica D: Nonlinear Phenomena},
volume = {15},
number = {1},
pages = {181-196},
year = {1985},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(85)90161-7},
url = {https://www.sciencedirect.com/science/article/pii/0167278985901617},
author = {T. Goldman and H.E. Haber},
abstract = {The ‘gluino’ (g̃) the Majorana spin-12 supersymmetric partner of the gluon, behaves like a new quark flavor which is a color octet. In analogy with quarkonium, there should exist a spectrom of g̃g̃ bound states which we will call gluinonia. The large color change leads to enhanced production rates (in both singlet and octet gluinonia states) in gluon-gluon scattering processes. We compute the rate for observing gluinonium in quarkonium decay and in high energy hadronic collisions. The signal-to-noise ratio is small, but may be observable. The non-observation of a pseudoscalar gluinonium state is radiative ψ decay probably rules out gluino masses less than 1 GeV/c2.}
}
@article{LOSEV1998549,
title = {Issues in topological gauge theory},
journal = {Nuclear Physics B},
volume = {534},
number = {3},
pages = {549-611},
year = {1998},
issn = {0550-3213},
doi = {https://doi.org/10.1016/S0550-3213(98)00628-2},
url = {https://www.sciencedirect.com/science/article/pii/S0550321398006282},
author = {A. Losev and N. Nekrasov and S. Shatashvili},
abstract = {We discuss topological theories, arising from the general N = 2 twisted gauge theories. We initiate a program of their study in the Gromov-Witten paradigm. We re-examine the low-energy effective abelian theory in the presence of sources and study the mixing between the various p-observables. We present the twisted superfield formalism which makes duality transformations transparent. We propose a scheme which uniquely fixes all the contact terms. We derive a formula for the correlation functions of p-observables on the manifolds of generalized simple type for 0 ⪕ p ⪕ 4 and on some manifolds with b2+ = 1. We study the theories with matter and explore the properties of universal instantons. We also discuss the compactifications of higher dimensional theories. Some relations to sigma models of type A and B are pointed out and exploited.}
}
@article{LI2021106918,
title = {Evaluating community question-answering websites using interval-valued intuitionistic fuzzy DANP and TODIM methods},
journal = {Applied Soft Computing},
volume = {99},
pages = {106918},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106918},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620308565},
author = {Ming Li and Ying Li and Qijin Peng and Jie Wang and Chunxia Yu},
keywords = {CQA service quality, DANP, TODIM, Multiple criteria decision-making, Interval-valued intuitionistic fuzzy set},
abstract = {As important knowledge-sharing platforms, community question-answering (CQA) websites have attracted the attention of many users. An evaluation of the quality of CQA websites can assist users in selecting high-quality CQA websites and can help the operators of CQA websites achieve the most beneficial improvements. An approach to the evaluation of CQA websites is proposed in this study. First, a CQA service quality model is constructed to evaluate the quality of CQA websites based on the E-SERVQUAL model. A novel multicriteria decision-making (MCDM) model is proposed to address the ratings. In the model, uncertainty and consistency are combined in an interval-valued intuitionistic fuzzy (IVIF) environment to determine two kinds of expert weights. The DANP method, along with experts’ weights, is extended to the IVIF environment to derive the criteria weights. The IVIF TODIM method, along with experts’ weights, is used to rank the CQA websites in terms of quality. Finally, the proposed approach is applied to evaluate the quality of five CQA websites. The experimental results of the application, along with sensitivity analysis and comparative analysis, demonstrate the feasibility and practicality of the proposed approach.}
}
@article{KAMAREDDINE1994183,
title = {A unified approach to type theory through a refined λ-calculus},
journal = {Theoretical Computer Science},
volume = {136},
number = {1},
pages = {183-216},
year = {1994},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(94)00127-5},
url = {https://www.sciencedirect.com/science/article/pii/0304397594001275},
author = {Fairouz Kamareddine and Rob Nederpelt},
abstract = {In the area of foundations of mathematics and computer science, three related topics dominate. These are λ-calculus, type theory and logic. There are moreover, many versions of λ-calculi and type theories. In these versions, the presence of logic ranges from the non-existent to the dominant. In fact, the three subjects of λ-calculus, logic and type theory, got separated due to the appearence of the paradoxes. Moreover, the existence of various versions of each topic is due to the need to get back to the lost paradise which allowed a great freedom in mixing expressivity and logic. In any case, the presence of such a variety of systems calls for a framework to unify them all. Barendregt's cube, for example, is an attempt to unify various type systems and his associated logic cube is an attempt to find connections between type theories and logic. We devise a new λ-notation which enables categorising most of the known systems in a unified way. More precisely, we sketch the general structure of a system of typed lambda calculus and show that this system has enough expressive power for the description of various existing systems, ranging from Automath-like systems to singly typed pure type systems. The system and the notation that we propose have far reaching advantages than just being used as a generalisation formalism. These advantages range from generalising reduction and substitution to representing Mathematics and are investigated in detail in various articles cited in the bibliography.}
}
@article{WAN2021107383,
title = {Interactive multi-criteria group decision-making with probabilistic linguistic information for emergency assistance of COVID-19},
journal = {Applied Soft Computing},
volume = {107},
pages = {107383},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107383},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621003069},
author = {Shu-Ping Wan and Wen-Bo {Huang Cheng} and Jiu-Ying Dong},
keywords = {Multi-criteria group decision-making, Probabilistic linguistic term set, Choquet integral operator, Archimedean copulas and co-copulas, Emergency assistance},
abstract = {This paper develops a new method for interactive multi-criteria group decision-making (MCGDM) with probabilistic linguistic information and applies to the emergency assistance area selection of COVID-19 for Wuhan. First, a new possibility degree for PLTSs is defined and a new possibility degree algorithm is devised to rank a series of probabilistic linguistic term sets (PLTSs). Second, some new operational laws of PLTSs based on the Archimedean copulas and co-copulas are defined. A generalized probabilistic linguistic Choquet (GPLC) operator and a generalized probabilistic linguistic hybrid Choquet (GPLHC) operator are developed and their desirable properties are discussed in details. Third, a tri-objective nonlinear programming model is constructed to determine the weights of DMs. This model is transformed into a linear programming model to solve. The fuzzy measures of criterion subsets are derived objectively by establishing a goal programming model. Fourth, using the probabilistic linguistic Gumbel weighted average (PLGWA) operator, the collective normalized decision matrix is obtained by aggregating all individual normalized decision matrices. The overall evaluation values of alternatives are derived by the probabilistic linguistic Gumbel hybrid Choquet (PLGHC) operator. The ranking order of alternatives is generated. Finally, an emergency assistance example is illustrated to validate the proposed method of this paper.}
}
@article{BRIDGES19741,
title = {Special partially balanced incomplete block designs and associated graphs},
journal = {Discrete Mathematics},
volume = {9},
number = {1},
pages = {1-18},
year = {1974},
issn = {0012-365X},
doi = {https://doi.org/10.1016/0012-365X(74)90068-5},
url = {https://www.sciencedirect.com/science/article/pii/0012365X74900685},
author = {W.G. Bridges and M.S. Shrikhande},
abstract = {This paper treats a class of combinatorial designs which are essentially partially balanced incomplete block designs with two associate classes and with the additional feature that there are constants s and t so that for any treatment-block pair (x, B), the number of first associates of x in the block B is s or t depending on whether x ϵ B or x ∉ B. We obtain necessary and sufficient conditions that a P.B.I.B.D. should have this feature and obtain generalizations of earlier results on triangular and L2 (n) P.B.I.B.D.'s. Finally, we consider two graphs naturally associated with quasi symmetric P.B.I.B.D.'s having this special feature determine their spectra, and investigate the conditions under which they are strongly regular.}
}
@article{GREEF199531,
title = {Implementation of a logic-based support system for concurrent engineering},
journal = {Data & Knowledge Engineering},
volume = {15},
number = {1},
pages = {31-61},
year = {1995},
issn = {0169-023X},
doi = {https://doi.org/10.1016/0169-023X(95)94024-3},
url = {https://www.sciencedirect.com/science/article/pii/0169023X95940243},
author = {Arthur R. Greef and Steffen M. Fohn and Robert E. Young and Peter J. O'Grady},
keywords = {Order-sorted logic, Concurrent engineering, Constraint satisfaction},
abstract = {In this paper we detail the representation and implementation techniques used to build SPARK, a logic-based support system for designers engaged in concurrent engineering. Design rules are represented as constraints in a constraint satisfaction problem. This problem is translated into equivalent order-sorted logic formulae that form a concurrent engineering logic problem. The solution to this problem is determined through interactive constraint satisfaction performed by a deduction system and associated proof strategy. This illustrated with an example from Printed Wiring Board Design.}
}
@article{ALABOOL2018161,
title = {Cloud service evaluation method-based Multi-Criteria Decision-Making: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {139},
pages = {161-188},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.01.038},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300244},
author = {Hamzeh Alabool and Ahmad Kamil and Noreen Arshad and Deemah Alarabiat},
keywords = {Cloud computing service, Cloud service evaluation method, Multi-Criteria Decision-Making (MCDM), Evaluation theory, Systematic literature review},
abstract = {A substantial effort has been made to solve the cloud-service evaluation problem. Different Cloud Service Evaluation Methods (CSEMs) have been developed to address the problem. Cloud services are evaluated against multiple criteria, which leads to a Multi-Criteria Decision-Making (MCDM) problem. Yet, studies that assess, analyse, and summarize the unresolved problems and shortcomings of current CSEM-based MCDM are limited. In the existing review studies, only individual parts of CSEMs, rarely the full solution, are reviewed and examined. To investigate CSEMs comprehensively, we present a systematic literature review based on Evaluation Theory, a theory that generalizes six evaluation components, target, criteria, yardstick, data gathering techniques, synthesis techniques, and evaluation process. These six evaluation components and the CSEMs validation approach are the seven dimensions used to assess and analyse 77 papers published from 2006 to 2016. Sixteen research deficiencies were identified. The results confirm that the majority of the studies of the proposed CSEMs were either incomplete or lacked sufficient evidence. This research not only provides the relative strengths and weaknesses of the different CSEMs but also offers a basis for researchers and decision makers to develop improved CSEMs.}
}
@article{YE2023634,
title = {Cross cultural Comparative Study on Emotional Analysis of Social Media},
journal = {Procedia Computer Science},
volume = {221},
pages = {634-641},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923007901},
author = {Liu Ye and Cheng Wei and Yin Yimeng},
keywords = {Text Mining, Sentiment analysis, Topic clustering, Cross cultural exchange},
abstract = {With the popularization of social media and the acceleration of globalization, cross-cultural social media research has become an increasingly important research field. This article takes cultural differences as the starting point to explore the use and impact of social media in cross-cultural environments. The study used a combination of quantitative and qualitative methods to collect social media data from users from different cultural backgrounds, and conducted data analysis and comparison. Research has found that users from different cultural backgrounds have significant differences in social media usage behavior, content expression, and interaction methods. At the same time, the use of cross-cultural social media will also have different impacts on users’ cultural identity, social relations and mental health. The research results have certain reference value for promoting cross-cultural communication, enhancing cultural understanding, and improving the effectiveness of social media usage.}
}
@article{LAKOWICZ1978202,
title = {Particulate enhanced membrane uptake of 1,2-benzanthracene observed by fluorescence spectroscopy: A possible role in co-carcinogenesis},
journal = {Biochimica et Biophysica Acta (BBA) - General Subjects},
volume = {543},
number = {2},
pages = {202-216},
year = {1978},
issn = {0304-4165},
doi = {https://doi.org/10.1016/0304-4165(78)90065-X},
url = {https://www.sciencedirect.com/science/article/pii/030441657890065X},
author = {Joseph R. Lakowicz and Finn Englund and Anders Hidmark},
abstract = {In recognition of the co-carcinogenic effect of particulate matter and chemical carcinogens, we investigated the effect of particulate silica on the rates of membrane uptake of 1,2-benzanthracene. The fluorescence emission spectra and the apparent quantum yields of benzathracene are dependent upon adsorption to silica and upon the surface density of benzathracene on the silica. The fluorescence spectral shifts which occur upon transfer of benzathracene from silica surface to phospholipid vesicles provided a convenient means to quantitate the membrane uptake of benzanthracene from particulates. The rate of benzathracene uptake by dipalmitoyl-L-α-phosphatidylcholine vesicles was independent of the concentration of lipid, indicating that the rate-limiting step may involve its sulubilization in the aqueous phase. These uptake rates were also independent of the surface density of benzanthracene on the silica, indicating that the benzanthracene molecules are dispersed uniformly on the silica surface. Rates of membrane uptake of benzanthracene from the crystalline, microcrystalline, and the silica-absorbed states were compared, and are greatly enhanced by a reduction in crystal size. Silica-adsorbed benzanthracene had the most rapid rate of membrane uptake. Silica did not cause disruption of the lipid vesicles. These results indicate that particulates can enhance the cellular availability of chemical carcinogens.}
}
@article{HON2005139,
title = {Performance and Evaluation of Manufacturing Systems},
journal = {CIRP Annals},
volume = {54},
number = {2},
pages = {139-154},
year = {2005},
issn = {0007-8506},
doi = {https://doi.org/10.1016/S0007-8506(07)60023-7},
url = {https://www.sciencedirect.com/science/article/pii/S0007850607600237},
author = {K.K.B. Hon},
keywords = {Manufacturing, System, Performance},
abstract = {The monitoring and control of the input and output of manufacturing systems is an essential task for the system optimisation. Performance of manufacturing systems covers a wide spectrum of technology and management activities. This paper reviews the historical evolution of and modern developments in manufacturing performance measurement within a systems framework based on five metrics and five levels from single workstation to the entire manufacturing network. A summary of an industrial survey in the aerospace industry is also included to provide an industrial perspective. The implications of emerging topics of growing importance in sustainability, agility, e-manufacturing, complexity and biomimetics are also discussed.}
}
@article{HALL1974267,
title = {The metabolism of ammonium fluoride and sodium monofluoroacetate by experimental Acacia georginae},
journal = {Environmental Pollution (1970)},
volume = {6},
number = {4},
pages = {267-280},
year = {1974},
issn = {0013-9327},
doi = {https://doi.org/10.1016/0013-9327(74)90015-9},
url = {https://www.sciencedirect.com/science/article/pii/0013932774900159},
author = {R.J. Hall},
abstract = {Plants of Acacia georginae (one of numerous toxic tropical species now known to contain monofluoroacetate) were cultivated in nutrient-washed quartz, and in soil. Attempts were made to induce the formation of organic fluorine by treatment of the roots with a solution of ammonium fluoride. Only small amounts of carbon-fluorine material were measured in the leaves and roots, and examinations by physico-chemical methods failed to detect any evidence of the presence of monofluoroacetate in any of the plants. Similar plants were treated with sodium monofluoroacetate which underwent considerable degradation to an acid-labile form of fluorine (probably inorganic fluoride). The results of the analyses of the roots and leaves for fluorine revealed that the difference between acid-labile (diffusible) fluoride and total fluorine cannot be taken as a measure of the organic fluorine.}
}
@article{CHEN2016279,
title = {Multicriteria decision making based on the TOPSIS method and similarity measures between intuitionistic fuzzy values},
journal = {Information Sciences},
volume = {367-368},
pages = {279-295},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.05.044},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516303838},
author = {Shyi-Ming Chen and Shou-Hsiung Cheng and Tzu-Chun Lan},
keywords = {Intuitionistic fuzzy values, Intuitionistic fuzzy sets, Multicriteria decision making, Similarity measure, TOPSIS method},
abstract = {Multicriteria decision making (MCDM) in intuitionistic fuzzy environments is a very important research topic. In this paper, we propose a new MCDM method based on the TOPSIS method and similarity measures between intuitionistic fuzzy values (IFVs). First, the proposed method calculates the degree of indeterminacy of each evaluating IFV given by the decision maker. Then, it gets the relative positive ideal solution and the relative negative ideal solution for the criteria, respectively. Then, it calculates the degrees of indeterminacy of the relative positive ideal value and the relative negative ideal value for each criterion, respectively. Then, it calculates the positive similarity degrees and the negative similarity degrees between the evaluating IFVs and the relative positive ideal solutions and the relative negative ideal solutions for the criteria, respectively. Finally, it calculates the weighted positive score and the weighted negative score of each alternative, respectively, to get the relative degree of closeness of each alternative. The larger the relative degree of closeness of the alternative, the better the preference order of the alternative. The experimental results show that the proposed method can overcome the drawbacks of Joshi and Kumar's method (2014), Wang and Wei's method (2008) and Wu and Chen's method (2011) for MCDM in intuitionistic fuzzy environments.}
}
@article{BITRAN1998169,
title = {A structured product development perspective for service operations},
journal = {European Management Journal},
volume = {16},
number = {2},
pages = {169-189},
year = {1998},
issn = {0263-2373},
doi = {https://doi.org/10.1016/S0263-2373(97)00086-8},
url = {https://www.sciencedirect.com/science/article/pii/S0263237397000868},
author = {Gabriel Bitran and Luis Pedrosa},
abstract = {In this paper we review the literature on product development from a services perspective. We identify similarities in the creation and evolution of products and services, and discuss three types of knowledge that are commonly required in a development process: the sequence of steps or procedural plan that must be followed; the understanding of what components integrate the design and how they interact (architectural knowledge); and the principles and models that describe physical or human behavior in the system that is being designed. For each step of a generic development process we review the methods and tools that are widely used in product development and may be successfully applied to service development. To illustrate the notion of architectural knowledge in the service context, we introduce an example of a service operation structure and discuss important aspects of its components. Finally we explain the role of models in the development of products and services and argue how they can help design intangible elements. We conclude the paper by identifying gaps in the literature and suggesting directions for future research.}
}
@article{EDGE2003511,
title = {The role of the surgeon in quality cancer care},
journal = {Current Problems in Surgery},
volume = {40},
number = {9},
pages = {511-590},
year = {2003},
issn = {0011-3840},
doi = {https://doi.org/10.1016/S0011-3840(03)00051-0},
url = {https://www.sciencedirect.com/science/article/pii/S0011384003000510},
author = {Stephen B Edge}
}
@incollection{YAMAMOTO199087,
title = {II Quantum Mechanical Limit in Optical Precision Measurement and Communication},
editor = {E. Wolf},
series = {Progress in Optics},
publisher = {Elsevier},
volume = {28},
pages = {87-179},
year = {1990},
issn = {0079-6638},
doi = {https://doi.org/10.1016/S0079-6638(08)70289-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079663808702890},
author = {Y. Yamamoto and S. Machida and S. Saito and N. Imoto and T. Yanagawa and M. Kitagawa and G. Björk},
abstract = {Publisher Summary
This chapter discusses the standard and intrinsic quantum mechanical limits on optical precision measurement and communication. Nonclassical lights, such as a quadrature amplitude squeezed state, number-phase squeezed state (number state), and correlated photon pair circumvent the standard quantum limit (SQL) on photon generation. A quantum mechanical limit on the minimum energy cost per bit emerges if an optical homodyne or heterodyne receiver is used instead of a photon counter. The SQL on photon amplification stems from the fact that an ordinary linear amplifier amplifies the two conjugate observables simultaneously. The chapter discuses the intrinsic quantum limit, which determines the information extraction from a light wave. It emerges in the form of quantum mechanical channel capacity and Bohr's time-energy uncertainty principle. Applications of nonclassical lights, QND measurements, and single-observable amplifiers are also discussed.}
}
@article{LIU201520,
title = {Economic MPC with Terminal Cost and Application to Oilsand Separation},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {8},
pages = {20-25},
year = {2015},
note = {9th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2015},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315010186},
author = {Su Liu and Jing Zhang and Jinfeng Liu},
keywords = {Nonlinear systems, Predictive control, Process optimization, Chemical processes},
abstract = {In this work, a novel approach to construct the terminal cost for economic model predictive control (EMPC) is developed. In the proposed approach, an auxiliary nonlinear controller which renders the desired optimal steady state asymptotically stable is taken advantage of. The proposed terminal cost is constructed such that it reflects the economic performance of the auxiliary controller over sufficiently large but finite steps. The proposed EMPC design provides guaranteed closed-loop economic performance which does not depend on the length of the prediction horizon. This means that the proposed EMPC algorithm could be very computationally efficient. The proposed EMPC algorithm is applied to an oilsand primary separation vessel. The simulation results demonstrate the effectiveness of the proposed approach.}
}
@article{VASSILAKIS1997341,
title = {Accelerating new product development by overcoming complexity constraints},
journal = {Journal of Mathematical Economics},
volume = {28},
number = {3},
pages = {341-373},
year = {1997},
issn = {0304-4068},
doi = {https://doi.org/10.1016/S0304-4068(97)00803-3},
url = {https://www.sciencedirect.com/science/article/pii/S0304406897008033},
author = {Spyros Vassilakis},
keywords = {New product development, Organization and management of technological innovation, Management of complexity},
abstract = {The economic theory of technological change is a theory of investment. Agents invest in an activity called research; a black box process returns a value for a variable that shifts the production function. This paper proposes a way to open the black box. It is motivated both by theoretical arguments for opening this box and by recent emperical literature on new product development that stresses the importance of nontraditional factors in determining firm performance. An example of the former is Solow: “… the production of new technology may not be a simple matter of inputs and outputs. I do not doubt that high financial returns to successful innovation will divert resources into R & D. The hard part is to model what happens then”. An example of the latter is Baily and Gersbach, who discuss the determinants of operating efficiency of firms. “Traditional determinants, such as capital intensity and scale were found to play a role. But innovations such as design for manufacturing and workplace organization turned out to be even more important”. This paper considers technological change, and in particular new product and process development, from a new perspective, that of complex problem solving. Technological change is made possible by organizational techniques that reduce the complexity of problem solving; differences in the technological performance of firms are attributed to their different problem-solving styles. More specifically, the paper identifies rework as the main reason and symptom of slow NPD, and proposes three techniques that provably minimize rework: problem decomposition, decision ordering, and communication before design.}
}
@article{HAGIWARA199441,
title = {Ecosystem modeling of a multi-species integrated aquaculture pond in South China},
journal = {Ecological Modelling},
volume = {72},
number = {1},
pages = {41-73},
year = {1994},
issn = {0304-3800},
doi = {https://doi.org/10.1016/0304-3800(94)90145-7},
url = {https://www.sciencedirect.com/science/article/pii/0304380094901457},
author = {Hiroyuki Hagiwara and William J. Mitsch},
abstract = {A model of an integrated aquaculture pond in Suzhou, China, was developed with phytoplankton, zooplankton, dissolved oxygen, phosphorus, silicon, detritus, sediment, and six species of fish: black carp (Mylopharyngodon piceus), common carp (Cyprinus carpio), Wuchang fish (Megalobrama amblycephala), silver carp (Hypophthalmichtys molitrix), grass carp (Ctenopharyngodon idella) and bighead carp (Aristichthys nobilis). All biological state variables were treated as concentration with energy units (kJ m−2). The model replicated observed changes in primary productivity, dissolved oxygen, and fish production using energy flow data collected from a black carp-common carp pond in China. Simulation results and sensitivity analysis suggested that through multiple feedback mechanisms, the pond ecosystem stabilizes itself. Removing any one species has significant effects on system behavior; simulated removal of fish species led to decreased overall fish production. The model identified future research needs in such areas as phosphorus release mechanisms, phytoplankton species composition, and toxic substances.}
}
@article{HANDFIELD1997293,
title = {‘Green’ value chain practices in the furniture industry},
journal = {Journal of Operations Management},
volume = {15},
number = {4},
pages = {293-315},
year = {1997},
issn = {0272-6963},
doi = {https://doi.org/10.1016/S0272-6963(97)00004-1},
url = {https://www.sciencedirect.com/science/article/pii/S0272696397000041},
author = {Robert B Handfield and Steve V Walton and Lisa K Seegers and Steven A Melnyk},
keywords = {Environmental issues, Government regulation, Case study research, Empirical research},
abstract = {This paper draws on the results of interviews with five environmental managers in the furniture industry to develop a taxonomy of environmentally-friendly (‘green’) best practices within the operations management value chain. This taxonomy is then extended to develop a group of propositions concerning the role of management in promoting environmentally-friendly practices. The results suggest that in order to be successful, environmental management strategies must be integrated into all stages of the value chain, which includes all of the processes spanning product design, procurement, manufacturing and assembly, packaging, logistics, and distribution. While the potential for environmental performance improvement in all five of the companies is evident, all of them demonstrated ‘pockets’ of environmentally-friendly practices (EFP) in different areas of their respective value chain functions. The propositions and results emerging from the analysis also suggests that reacting to regulations is no longer sufficient. World-class EFP must anticipate and pre-empt changing environmental regulations and customer expectations, and proactively prepare products, processes and infrastructure for these changes without sacrificing competitive advantage.}
}
@article{SASSEDWIGHT1990945,
title = {Role of eukaryotic-type functional domains found in the prokaryotic enhancer receptor factor σ54},
journal = {Cell},
volume = {62},
number = {5},
pages = {945-954},
year = {1990},
issn = {0092-8674},
doi = {https://doi.org/10.1016/0092-8674(90)90269-K},
url = {https://www.sciencedirect.com/science/article/pii/009286749090269K},
author = {Selina Sasse-Dwight and Jay D. Gralia},
abstract = {E. coli σ54 protein confers on promoters containing its recognition sequence the ability to be activated from distant DNA sites. Its functional domains include two leucine zipper motifs, an acidic region, and a glutamine-rich domain. Several domains were disrupted and the assembly of mutant transcription complexes was probed in vivo by footprinting. Promoter recognition was seen to depend on a C-terminal region containing a prokaryotic helix-turn-helix motif. Within the resulting stable closed complex, two leucine zipper motifs assist in positioning the σ54 polymerase near the DNA region that must be meited upon activation. Finally, DNA opening depends on the σ54 acid domain. The uncoupling of promoter recognition from DNA melting, mediated by the unusual domain structure of this prokaryotic protein, may be responsible for σ54's ability to mediate activation from distant sites.}
}
@article{BERGNER1961359,
title = {Tracer dynamics: II. The limiting properties of the tracer system},
journal = {Journal of Theoretical Biology},
volume = {1},
number = {3},
pages = {359-381},
year = {1961},
issn = {0022-5193},
doi = {https://doi.org/10.1016/0022-5193(61)90037-6},
url = {https://www.sciencedirect.com/science/article/pii/0022519361900376},
author = {Per-Erik E. Bergner},
abstract = {This continuation of a previous paper is mainly concerned with an analysis of the “finite tracer system”, i.e. the system composed of a finite number of mutually exclusive and uniform compartments (here called subsystems). Special attention is paid to the limiting properties of that system and to the connection between the tracer and its mother substance. The results of the analysis are summarized in the form of a number of theorems and it is shown that their validity can be extrapolated to the more general tracer system with non-uniform compartments. The consequences of that are briefly indicated: it is shown that the possibility of treating non-uniform compartments seems to imply a simplification of the theory in a case like the closed system of plasma and red blood cells. A fundamental property of the present approach is that the fluxes are expressed as functions of the total amounts and not of the concentrations of the actual substance, and, as pointed out in the introduction, this indicates an improvement as regards the significance of the observed variables.}
}
@article{JOOS1999161,
title = {A methodology for multi-objective design assessment and flight control synthesis tuning},
journal = {Aerospace Science and Technology},
volume = {3},
number = {3},
pages = {161-176},
year = {1999},
issn = {1270-9638},
doi = {https://doi.org/10.1016/S1270-9638(99)80040-6},
url = {https://www.sciencedirect.com/science/article/pii/S1270963899800406},
author = {H.-D. Joos},
keywords = {multi-objective design, quality functions, objectives in flight control design, flight control law design, min-max parameter optimisation, Mehrzieliger Entwurf, Qualitätsfunktionen, Kriterien der Flugregelung, Flugregelung, Min-Max-Parameteroptimierung},
abstract = {Flight control law design is a multi-variable control problem where various strict requirements from multiple disciplines have to be satisfied. This paper describes quality function deployment and its use in multi-objective control synthesis tuning and design assessment, with application to flight control design. The main feature of this methodology is that the various kinds of design objectives can be taken into account in their most natural form and design alternatives can be assessed most visibly with respect to given requirements. Multi-objective synthesis tuning by min-max parameter optimisation allows interactive compromising in the set of what can be best-possibly achieved with a chosen control law structure.
Zusammenfassung
Der Entwurf von Flugregelungsgesetzen ist ein Mehrgrößenproblem, bei dem Anforderungen von verschiedenen Fachdisziplinen strikt erfüllt werden müssen. Dieser Beitrag beschreibt die Entwicklung von Qualitätsfunktionen und deren Verwendung für eine mehrzielige Flugreglersynthese mit begleitendem Entwurfsassessment. Die wichtigsten Vorteile dieser Methode liegen in der Möglichkeit, die verschiedenartigsten Entwurfsziele in ihrer durch die Spezifikationen gegeben Form schon während des Entwurfs direkt berücksichtigen und zusätzlich Entwurfsalternativen objektiv bewerten zu können. Die Verwendung von Min-Max-Parameteroptimierungsverfahren für die Synthese ermöglichen es, für eine gegebene Reglerstruktur in interaktiver Weise Kompromißlösungen in der Menge der bestmöglichen Entwurfsalternativen zu finden.}
}
@article{TENG1996271,
title = {Developing strategic perspectives on business process reengineering: From process reconfiguration to organizational change},
journal = {Omega},
volume = {24},
number = {3},
pages = {271-294},
year = {1996},
issn = {0305-0483},
doi = {https://doi.org/10.1016/0305-0483(96)00001-1},
url = {https://www.sciencedirect.com/science/article/pii/0305048396000011},
author = {J.T.C. Teng and V. Grover and K.D. Fiedler},
keywords = {business process, reengineering, MIS, strategic planning, implementation, change management},
abstract = {Successful business process reengineering (BPR) efforts in many firms have been reported to significantly improve productivity and reduce staff. However, as the reality of large-scale process change sets in and reengineering failures start coming to the forefront, more careful thought must be given to the change process itself, and it is important that senior leaders in the organization develop a high-level strategic perspective on this multifaceted change phenomenon. To help develop this perspective, a process reconfiguration model and a framework of organizational change in BPR are presented in this paper. The process reconfiguration model shows how various functional activities involved in a business process may be reconfigured through a reengineering initiative. Such fundamental reconfigurations may be facilitated by the application of IT as well as a number of innovative organizational changes. Building upon this process reconfiguration model, a framework depicting elements of organizational change associated with BPR is presented. The framework identifies the various sources of changes, elements of change implementation, and the direction of organizational change stemming from BPR. It is hoped that based on this framework, we may be better able to plan and implement the complex process of organizational change associated with BPR.}
}
@incollection{NOVAK198125,
title = {Chapter 3 Identification and quantitation},
editor = {J. Drozd},
series = {Journal of Chromatography Library},
publisher = {Elsevier},
volume = {19},
pages = {25-51},
year = {1981},
booktitle = {Chemical Derivatization in Gas Chromatography},
issn = {0301-4770},
doi = {https://doi.org/10.1016/S0301-4770(08)61052-0},
url = {https://www.sciencedirect.com/science/article/pii/S0301477008610520},
author = {Josef Novák},
abstract = {Publisher Summary
This chapter discusses concepts and methods employed in the identification of compounds and their determination by gas chromatography (GC). Procedures for the identification of compounds by GC constitute a very broad and varied discipline. There are many possibilities in this respect, and the proper choice in a particular instance is dependent on the nature of the problem and the equipment available. Basically, GC is a separation method, but it's very high separation efficiency confers upon retention characteristics a significant identification virtue and greatly facilitates the use of various ancillary identification techniques. The basis of quantitative analysis by modern methods of column elution chromatography can be specified as the chromatographic separation of an n-component mixture into n binary (or pseudo-binary) component-mobile phase mixtures and the continuous measurement of the contents of the separated components in these mixtures with the aid of a special analyzer. The function of this analyzer is performed by the chromatographic detector, together with the system for recording and processing the chromatographic data. The range of applicability of analytical chromatography is qualified above all by the standard of chromatographic instrumentation; the role of instrumentation is particularly important from the point of view of the definition of chromatography as a quantitative analytical method.}
}
@article{CERDEIRAL201956,
title = {Software project management in high maturity: A systematic literature mapping},
journal = {Journal of Systems and Software},
volume = {148},
pages = {56-87},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302218},
author = {Cristina T. Cerdeiral and Gleison Santos},
keywords = {Quantitative project management, High maturity project management, Maturity models},
abstract = {High maturity in software development involves statistically controlling the performance of critical subprocesses and using the predictability thus gained to manage projects with better planning precision and monitoring control. Maturity models such as CMMI mention statistical and other quantitative methods, techniques, and tools supporting high-maturity project management, but do not provide details about them, their use or their available types. Thus, knowledge is lacking on how to support software process improvement initiatives to select and apply statistical and other quantitative methods, techniques and tools in this context. The goal of this study is to identify various methods, techniques, and tools which can assist in high-maturity software project management. By conducting a systematic literature mapping, we identified 108 papers describing 153 contributions. We describe the contributions identified, classifying them by their type, their software technology maturation phase, the method by which they were evaluated, the development methods and characteristics which they support, and the process/indicator areas to which they were applied. We hope this work can help fill the knowledge gap on the statistical and other quantitative methods, techniques and tools actually being proposed, evaluated, experimented with and adopted by organizations to support quantitative high-maturity software project management.}
}
@article{ROBSON19878,
title = {Expert system for protein engineering: its application in the study of chloramphenicol acetyltransferase and avian pancreatic polypeptide},
journal = {Journal of Molecular Graphics},
volume = {5},
number = {1},
pages = {8-17},
year = {1987},
issn = {0263-7855},
doi = {https://doi.org/10.1016/0263-7855(87)80038-3},
url = {https://www.sciencedirect.com/science/article/pii/0263785587800383},
author = {Barry Robson and Eric Platt and Robert V Fishleigh and Alan Marsden and Peter Millard},
keywords = {chemical structure + prediction, protein structure, chloramphenicol acetyltransferase, avian pancreatic polypeptide, homology, molecular graphics, template pattern matching, hydrophobic packing, expert systems},
abstract = {Lucifer is a suite of programs for the conformational study of drugs, proteins and other biomolecules. The overall architecture and operation of the suite is outlined with worked examples. New procedures are also described for the identification of secondary structure template similarity based on theorem-proof algebra and for the rapid evaluation of the hydrophobic packing of a protein conformation. These are discussed in relation to the molecular-graphics modelling of chloramphenicol acetyltransferase. Although Lucifer is of proven worth for the study of biological peptides and for protein modelling against homologues, its applicability to de novo protein structure prediction is untested. A preliminary study of avian pancreatic polypeptide is of this character and is described here. The results of the above attempts are both informative and promising.}
}
@incollection{KAWASHIMA198915,
title = {The Navier-Stokes Equation Associated with the Discrete Boltzmann Equation},
editor = {Masayasu Mimura and Takaaki Nishida},
series = {North-Holland Mathematics Studies},
publisher = {North-Holland},
volume = {160},
pages = {15-30},
year = {1989},
booktitle = {Recent Topics in Nonlinear PDE IV},
issn = {0304-0208},
doi = {https://doi.org/10.1016/S0304-0208(08)70504-8},
url = {https://www.sciencedirect.com/science/article/pii/S0304020808705048},
author = {Shuichi Kawashima and Yasushi Shizuta},
abstract = {Publisher Summary
This chapter is a summary of the work concerning the Navier-Stokes equation derived from the discrete Boltzmann equation. It considers a model of gas whose molecular velocities are restricted to a set of m constant vectors v1, ,vm in IRn. The purpose of this chapter is to study the hydrodynamical equations derived from the discrete Boltzmann equation by applying the Chapman-Enskog method. This chapter shows that the Navier-Stokes equation is transformed into a symmetric system by change of the dependent variable. It is known that the Navier-Stokes equation can be transformed into a coupled system of a symmetric hyperbolic system and a symmetric strongly parabolic system, by changing the dependent variable from w t o u.}
}
@article{DYSON1968435,
title = {Optimum distributed feed reactor with temperature constraints},
journal = {Chemical Engineering Science},
volume = {23},
number = {5},
pages = {435-446},
year = {1968},
issn = {0009-2509},
doi = {https://doi.org/10.1016/0009-2509(68)87019-8},
url = {https://www.sciencedirect.com/science/article/pii/0009250968870198},
author = {D.C. Dyson and J.R. Graves},
abstract = {Chemical reactors for a single exothermic reversible reaction with minimum volume for a given duty are considered in which the temperature is controlled directly by bypassing cold feed around a main feed preheater and distributing it along the length of the reactor, and in which the temperature may not exceed a given number: T̄. In general the optimal policy requires that in the first part of the reactor the cold feed be added in such a way that the temperature is maintained equal to T̄, in the second part the rate of addition of cold feed must be such that the reaction rate is maximized with respect to variations of the mass flow rate at each point (of the second part) of the reactor, and in the last part no cold feed must be added at all. A numerical example (the commercial air oxidation of SO2 to SO3) is presented.
Résumé
Des réacteurs chimiques sont considérés pour une seule réaction exothermique réversible avec un volume minimum pour un travail donné, la température dans le réacteur étant contrôlée directement par un refroidissement en by-pass autour d'un réchauffeur principal d'alimentation et le long du réacteur. La température ne doit pas exéder un nombre donné T̄. En général, la ligne optimale exige que le refroidissement se fasse dans la première partie du réacteur, de telle sorte que la température reste égale à T̄ Dans la deuxième partie, l'apport froid doit être tel que le taux de réaction soit à son maximum, en ce qui concerne les variations du taux d'écoulement de la masse à chaque point (de la deuxième partie) du réacteur, et, dans la dernière partie, aucun apport froid n'est nécessaire. Un exemple numérique (l'oxydation commerciale de SO2 en SO3) est présenté.
Zusammenfassung
Es werden chemische Reaktoren für eine einfache, exotherme, umkehrbare Reaktion mit Minimalvolumen für eine bestimmte Aufgabe behandelt, in welchen die Temperatur direkt reguliert wird und zwar durch die Umleitung von kaltem Einsatzmaterial um den Haupteinsatzvorwärmer, und Verteilung dieses Materials über die Länge des Reaktors hin, und in welchen die Temperatur einen gegebenen Wert T̄ nicht überschreiten darf. Im allgemeinen ist es für die optimal Regelung notwendig, dass im ersten Teil des Reaktors das kalte Einsatzmaterial in der Weise zugegeben wird, dass die Temperatur auf dem Wert T̄ bleibt, während im zweiten Teil das Mass der Zugabe derartig sein muss, dass die Reaktionsgeschwindigkeit im Hinblick auf Variationen in der Massendurchsatzgeschwindigkeit an jeder Stelle (des zweiten Teiles) des Reaktors maximiert wird. Im letzten Teil des Reaktors darf überhaupt kein kaltes Einsatz-material zugesetzt werden. Es wird ein zahlenmässiges Beispiel (die kommerzielle Luftoxydierung von SO2 zu SO3) angeführt.}
}
@article{AZARANGA1998265,
title = {An empirical investigation of the relationship between quality improvement techniques and performance—A Mexican case},
journal = {Journal of Quality Management},
volume = {3},
number = {2},
pages = {265-292},
year = {1998},
issn = {1084-8568},
doi = {https://doi.org/10.1016/S1084-8568(99)80117-5},
url = {https://www.sciencedirect.com/science/article/pii/S1084856899801175},
author = {Mohammad R. Azaranga and Graciela Gonzalez and Lawrie Reavill},
abstract = {Internationally, manufacturers are facing increasing competitive pressure resulting from liberalization of inter-country trading practices and consumer demands. Trade barriers, such as tariffs, are being reduced or have been removed altogether. Additionally, the regional free-trade agreements, such as U.S.-Canada-Mexico Free Trade Agreements, and the European Community (EC), have opened national boundaries to intea-regional trade. Many Mexican companies which relied on cheap labor and had little outside competition are now, threatened by technically more advanced companies. During the last decade, many Mexican companies have been adopting “world class” management practices and manufacturing techniques such as Total Quality Management, and Just-In-Time. How do these techniques impact the performance of the Mexican companies? This paper explores the effects of Total Quality Management (TQM), Work Teams (WT), and Just-In-Time (JIT) on a sample of 122 large manufacturing companies in Mexico. Sixty-eight different quality improvement techniques are correlated with seven different performance measures. Exploratory factor analysis was used to produce reliable and valid measures of the quality and productivity measures. The study used Canonical correlation methods to correlate simultaneously the quality improvement techniques to the performance measures. The finding indicates that top management involvement, employee involvement, and training impact quality, productivity, customer satisfaction, and employee morale simultaneously.}
}
@incollection{MANDELKOW1986612,
title = {[58] Cryo-electron microscopy of unstained frozen-hydrated microtubules},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {134},
pages = {612-633},
year = {1986},
booktitle = {Structural and Contractile Proteins Part C: The Contractile Apparatus and the Cytoskeleton},
issn = {0076-6879},
doi = {https://doi.org/10.1016/0076-6879(86)34126-0},
url = {https://www.sciencedirect.com/science/article/pii/0076687986341260},
author = {Eva-Maria Mandelkow and Eckhard Mandelkow}
}
@incollection{MOSTOWSKI1979311,
title = {On a generalization of quantifiers},
editor = {Andrzej Mostowski},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {93},
pages = {311-335},
year = {1979},
booktitle = {Foundational Studies},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(09)70266-6},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X09702666},
author = {A. Mostowski},
abstract = {Publisher Summary
This chapter deals with operators that represent a natural generalization of the logical quantifiers and formulates, for the generalized quantifiers, problems that correspond to the classical problems of the first-order logic. Some of these problems are solved in this chapter. Most of the discussion centers on the problem—whether it is possible to set up a formal calculus that would enable to prove all true propositions involving the new quantifiers. Although this problem is not solved in its full generality, it is clear from the partial results that are discussed in the chapter that the answer to the problem is essentially negative. Despite this negative result, it is believed that some of the generalized quantifiers deserve a closer study and some deserve even to be included into systematic expositions of symbolic logic. This belief is based on the conviction that the construction of formal calculi is not the unique and even not the most important goal of symbolic logic.}
}
@article{RUBIN19703579,
title = {Stereochemical relations in the bornane series: An example of preferred exo attack},
journal = {Tetrahedron},
volume = {26},
number = {14},
pages = {3579-3589},
year = {1970},
issn = {0040-4020},
doi = {https://doi.org/10.1016/S0040-4020(01)92937-0},
url = {https://www.sciencedirect.com/science/article/pii/S0040402001929370},
author = {M.B. Rubin and J.M. Ben-Bassat},
abstract = {The four α-hydroxybornanones have been obtained as their crystalline p-chlorobenzoates; the two endo ketoesters via photochemical reaction of camphorquinone and p-chlorobenzaldehyde and the two exo-isomers from cis, exo-bornanediol. cis-Diols were produced in every case by reaction of these ketoersters with p-methylbenzyl magnesium chloride, the endo-ketoesters affording cis, endo-diols via exo attack of the Grignard reagent on the bornane system. Two of the possible trans-diols were also synthesized.}
}
@article{FUJII199253,
title = {Selectivity and characteristics of direct contact membrane distillation type experiment. I. Permeability and selectivity through dried hydrophobic fine porous membranes},
journal = {Journal of Membrane Science},
volume = {72},
number = {1},
pages = {53-72},
year = {1992},
issn = {0376-7388},
doi = {https://doi.org/10.1016/0376-7388(92)80056-P},
url = {https://www.sciencedirect.com/science/article/pii/037673889280056P},
author = {Yoshishige Fujii and Shoji Kigoshi and Hidetsugu Iwatani and Masatoshi Aoyama},
keywords = {direct contact membrane, distillation, fine porous membrane, hollow fiber, alcohol selectivity, poly(vinylidene fluoride), polysulfone},
abstract = {Permeability and selectivity through fine porous membranes of hydrophobic polymers and direct contact membrane distillation (DCMD) type separation with such membranes have been studied. The permeability of an organic solute in dilute aqueous solution through the dried hollow fiber membranes depends on the partial vapor pressure of the solute. The selectivity for alcohol observed in a pervaporation type experiment depends on the ratio of the mean pore radius of the membrane to the radius of the alcohol molecule. The fluxes of ethanol and water in DCMD type separation are directly proportional to the partial vapor pressure differences, and the selectivity for ethanol varies with the properties of the polymers and the membranes. Polarization of temperature and concentration and heat transport characteristics are also studied.}
}
@article{DONAU1973109,
title = {Boson description of collective states: (II). Description of odd vibrational nuclei},
journal = {Nuclear Physics A},
volume = {209},
number = {1},
pages = {109-124},
year = {1973},
issn = {0375-9474},
doi = {https://doi.org/10.1016/0375-9474(73)90055-9},
url = {https://www.sciencedirect.com/science/article/pii/0375947473900559},
author = {F. Dönau and D. Janssen},
abstract = {By addition of the so-called ideal quasiparticle to the boson space one can represent the odd fermion states in that product space. In such a way one finds various representations of the fermion operators in terms of the boson operators and ideal quasiparticles. From these boson expansions of the fermion operators a finite one is selected by considering non-unitary transformations. Thus, the direct generalization, of the Dyson representation for even systems is given for the case of odd systems. The Hamiltonian can be divided into three parts: the boson term which describes the vibrational motion of the even core, the unperturbed motion of the quasiparticle, and the interaction between the quasiparticle and the bosons. This interaction consists of two terms, one of which agrees with the term used by Kisslinger and Sorensen 2), which is usually called the dynamical interaction, and the additional term is due to the antisymmetrization between the extra particle and the even core. The latter term can be identified as kinematical interaction which is responsible for the anomalous coupling states. For example, it is demonstrated that this term produces qualitatively the same splitting of the one-phonon multiplet as was obtained by Kuriyama et al. 3) for the j-shell. Furthermore, it is shown for the more complicated case of 117Sn that the effect of this additional interaction between phonons and quasiparticle is important when many shells to the states in the odd nucleus are taken into account.}
}
@article{JARKE1999229,
title = {Architecture and quality in data warehouses: An extended repository approach},
journal = {Information Systems},
volume = {24},
number = {3},
pages = {229-253},
year = {1999},
note = {10th International Conference on Advanced Information Systems Engineering},
issn = {0306-4379},
doi = {https://doi.org/10.1016/S0306-4379(99)00017-4},
url = {https://www.sciencedirect.com/science/article/pii/S0306437999000174},
author = {Matthias Jarke and Manfred A. Jeusfeld and Christoph Quix and Panos Vassiliadis},
keywords = {Data Warehouses, Meta Data Management, Data Quality, Conceptual Models, Repository},
abstract = {Most database researchers have studied data warehouses (DW) in their role as buffers of materialized views, mediating between update-intensive OLTP systems and query-intensive decision support. This neglects the organizational role of data warehousing as a means of centralized information flow control. As a consequence, a large number of quality aspects relevant for data warehousing cannot be expressed with the current DW meta models. This paper makes two contributions towards solving these problems. Firstly, we enrich the meta data about DW architectures by explicit enterprise models. Secondly, many very different mathematical techniques for measuring or optimizing certain aspects of DW quality are being developed. We adapt the Goal-Question-Metric approach from software quality management to a meta data management environment in order to link these special techniques to a generic conceptual framework of DW quality. The approach has been implemented in full on top of the ConceptBase repository system and has undergone some validation by applying it to the support of specific quality-oriented methods, tools, and application projects in data warehousing.}
}
@article{HOORN1994187,
title = {An environmental reconstruction of the palaeo-Amazon River system (Middle–Late Miocene, NW Amazonia)},
journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
volume = {112},
number = {3},
pages = {187-238},
year = {1994},
issn = {0031-0182},
doi = {https://doi.org/10.1016/0031-0182(94)90074-4},
url = {https://www.sciencedirect.com/science/article/pii/0031018294900744},
author = {Carina Hoorn},
abstract = {New sedimentological and palynological data from the Tertiary sediments in the Upper Amazon River area suggest that these sediments are fluvio-lacustrine deposits of Middle to Late Miocene age. They were generated as a result of the uplift of the Eastern Cordillera (Andes) and constitute possibly the oldest relics of the Amazon River system. The palaeoenvironment in which these sediments were deposited is characterized by extensive wetlands environments formed by swamps, shallow lakes, crevasse splay channels and crevasse-delta lakes where the channel environment is poorly represented. The palaeovegetation was dominated by palms (e.g. Mauritia and Grimsdalea), riverine taxa (e.g. Bombacaceae, Amanoa and Alchornea), ferns and fern allies (e.g. Polypodiaceae and Selaginellaceae), floating meadows (Gramineae) and aquatic taxa (Ceratopteris, Botryococcus and Azolla). The relative abundance of Gramineae and the occurrence of Andean-type pollen taxa is related to the Andean origin of the fluvial system. The varzeas of the present Upper Amazon River flood-basin are probably the best analogue for the Middle to Late Miocene environment. Intervals rich in marine palynomorphs, mangrove pollen, brackish tolerant molluscs and ostracods, and ichnofossils of the Thalassinoides-Teichichnus association suggest that the palaeoenvironment was characterized by brackish conditions and marine influence. These marine incursions are possibly related to the Langhian and the Serravallian global sea-level rise. Although in the Middle Miocene a global cooling is known to have occurred, no indicators of a cooler climate have been observed in the Miocene palynoflora of the Upper Amazon River area. Finally, four new sporomorph species are described belonging to the form-genera Psilatriletes, Clavainaperturites and Psilaperiporites.}
}
@article{SUZUKI1907265,
title = {A Study of the Proteolytic Changes Occurring in the Lima Bean During Germination},
journal = {Journal of Biological Chemistry},
volume = {3},
number = {4},
pages = {265-277},
year = {1907},
issn = {0021-9258},
doi = {https://doi.org/10.1016/S0021-9258(17)45982-5},
url = {https://www.sciencedirect.com/science/article/pii/S0021925817459825},
author = {Shinkichi Suzuki}
}
@article{GUPTA1996497,
title = {Changing patterns in industrial R&D management},
journal = {Journal of Product Innovation Management},
volume = {13},
number = {6},
pages = {497-511},
year = {1996},
issn = {0737-6782},
doi = {https://doi.org/10.1016/S0737-6782(96)00051-3},
url = {https://www.sciencedirect.com/science/article/pii/S0737678296000513},
author = {Ashok K. Gupta and David Wilemon},
abstract = {A successful R&D manager is, in many ways, an agent of change. R&D managers must respond effectively to changes in domestic and global competition, product and process technologies, customer requirements, regulatory matters, and senior management's perception of the role R&D plays in a firm. The responses to these changes flow downstream from R&D to other parts of the organization, in the form of new materials, methods, processes, and products. To help us understand the changes facing R&D management, Ashok K. Gupta and David Wilemon present the results of a study that examines the ideas and experiences of 120 R&D directors from technology-based companies. The study explores the major changes that R&D management has undergone in recent years, the changes R&D managers expect to encounter during the next few years, and the causes of those changes. The respondents also identify the skills and knowledge they view as necessary for effective R&D management, and they assess their organizations' capabilities in those areas. According to the respondents, major changes that R&D has encountered include increased emphasis on such issues as cross-functional teamwork, R&D's contribution to both short- and long-term business results, R&D's capability to quickly bring to market new products that customers value, efficient use of R&D resources, and R&D alliances. Other changes noted by respondents include greater pressure to find new markets, increased attention on the effective management of technical personnel, and increased regulations and sensitivity to environmental issues. The knowledge domains that the respondents highlighted as having the greatest effect on R&D performance include such capabilities as understanding customer needs, monitoring market developments, commercializing new technologies, building cross-functional teams, managing multiple R&D projects, and accelerating new product development. According to the respondents, the largest gaps between required and current capabilities exist in several of the areas listed as being most important to effective R&D management, including monitoring market developments that can affect R&D activities and overall business performance, maintaining a spirit of inquiry while ensuring that R&D contributes to overall corporate performance, developing technology commercialization capabilities, fostering mutually profitable strategic alliances, and accelerating the development and commercialization of new products.}
}
@article{DONNACHIE1962594,
title = {Dispersion relations for the photodisintegration of the deuteron},
journal = {Nuclear Physics},
volume = {37},
pages = {594-623},
year = {1962},
issn = {0029-5582},
doi = {https://doi.org/10.1016/0029-5582(62)90292-4},
url = {https://www.sciencedirect.com/science/article/pii/0029558262902924},
author = {A. Donnachie},
abstract = {The calculation of the matrix element for deuteron photodisintegration is considered. There are twelve invariant amplitudes. The covariant form of the transition amplitude is related to the non-covariant (Pauli-matrix) form, which is further related to the individual multipole transition amplitudes. The Born terms of the covariant amplitudes are derived, and the dispersion relations written down in energy for a fixed difference in the photon-proton and photon-neutron momentum transfers. It is necessary to use this rather than a fixed momentum transfer, in order to exhibit explicitly all the poles in the dispersion relations. The dispersion relations are restricted to dipole and quadrupole transitions, and by considering the relations at two different momentum transfers, equations are obtained explicitly for the individual electric dipole and magnetic dipole spin-flip transition amplitudes. The equations are solved in a low energy approximation in which the final n-p state rescattering cut and singlepion exchange cut only are considered, for the two cases of Gammel-Thaler type and Signell-Marshak phase-shifts. The results obtained are compared with the conventional results for the two cases, and with experiment.}
}
@article{WINTERBON1975293,
title = {An analytic theory of Doppler-shift attenuation},
journal = {Nuclear Physics A},
volume = {246},
number = {2},
pages = {293-316},
year = {1975},
issn = {0375-9474},
doi = {https://doi.org/10.1016/0375-9474(75)90647-8},
url = {https://www.sciencedirect.com/science/article/pii/0375947475906478},
author = {K.B. Winterbon},
abstract = {The treatment of the author's earlier exact analysis of Doppler shifts of γ-spectra is improved. The analysis remains exact within the Lindhard theory of slowing down of heavy ions in solids, while calculations using a realistic scattering cross section and including electronic stopping are facilitated. Besides the first moment, F(τ), of the Doppler-shifted spectrum, higher moments of the spectrum and the spectrum itself can be calculated. It is pointed out that the cumulative spectrum — i.e. the indefinite integral of the spectrum — is more easily and reliably calculated than the spectrum itself. Comparisons are made with calculations by the Blaugrund method and with experiment.}
}
@article{LIAO2019450,
title = {Novel operations of PLTSs based on the disparity degrees of linguistic terms and their use in designing the probabilistic linguistic ELECTRE III method},
journal = {Applied Soft Computing},
volume = {80},
pages = {450-464},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619302091},
author = {Huchang Liao and Lisheng Jiang and Benjamin Lev and Hamido Fujita},
keywords = {Multiple criteria analysis, Probabilistic linguistic term set, ELECTRE III, Distillation process, Nurse–patient relationship},
abstract = {The probabilistic linguistic term set (PLTS), which allows people to give their qualitative preferences in linguistic terms with corresponding probabilities, is a powerful form to express people’s preferences. This paper proposes a new ELECTRE III method to address multiple criteria decision-making (MCDM) problems based on novel operations of PLTSs. The new operations, including the addition, subtraction, and division of PLTSs are developed by considering the disparity degrees of linguistic terms. Then, novel concepts named the standard vector and gap function of PLTSs are introduced to represent the errors caused by the cognition differences of assessors. After transforming cost and target-based criteria to beneficial criteria, we define the concordance index, discordance index and outstanding degrees in PLTSs. The distillation process and Borda rule are used to obtain the final ranking of alternatives. After giving the algorithm of the probabilistic linguistic ELECTRE III (PL-ELECTRE III) method, we implement it to solve a problem concerning the nurse–patient relationship with the modified Okatani Keyco nurse–patient relationship trust scale. Comparisons between our method and other two methods are provided to demonstrate the advantages of the PL-ELECTRE III method.}
}
@article{CHETTY198333,
title = {On the effectiveness of monetary and fiscal policies in a Keynesian model},
journal = {European Economic Review},
volume = {23},
number = {1},
pages = {33-54},
year = {1983},
issn = {0014-2921},
doi = {https://doi.org/10.1016/0014-2921(83)90004-1},
url = {https://www.sciencedirect.com/science/article/pii/0014292183900041},
author = {V.K. Chetty and A.K. Lahiri},
abstract = {One of the central problems in macroeconomics is the comparison of the effectiveness of various monetary and fiscal policy measures for regulating output and employment. Opinions on this issue are quite varied. This paper analyses this controversy in the framework of a non-Walrasian model with price rigidities. It studies a monetary economy where money is the sole medium of exchange in the model ‘money buys goods and goods buy money; but goods do not buy goods’. The works of Benassy, Dreze, Malinvaud and Younes are utilised for constructing a model of Keynesian unemployment equilibrium.}
}
@article{NAIR2006948,
title = {Meta-analysis of the relationship between quality management practices and firm performance—implications for quality management theory development},
journal = {Journal of Operations Management},
volume = {24},
number = {6},
pages = {948-975},
year = {2006},
note = {Incorporationg Behavioral Theory in OM Empirical Models},
issn = {0272-6963},
doi = {https://doi.org/10.1016/j.jom.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0272696305001440},
author = {Anand Nair},
keywords = {Quality management, Performance, Theory development, Meta-analysis},
abstract = {Quality management (QM) has received a high degree of attention in extant literature. Several research papers attribute superior firm performance to adoption of QM practices. The availability of a large number of research papers that investigate the impact of QM practices on performance provide an ideal setting for theory extension and refinement using meta-analysis techniques. In this paper a meta-analytic study is presented that fulfills two objectives. First, the paper formalizes performance implications of adopting QM practices and present hypothesized relationship between QM practices and performance. Second, a meta-analysis of correlation (Hunter and Schmidt, 1990) approach is used to examine the empirical research in QM to determine which QM practices are positively related to improved performance. The study also examines the presence of moderating factors in the association between QM practices and performance. The results support many hypothesized relationships and also point towards the presence of moderating factors in almost all QM practice–performance relationships. A discussion of the findings is presented and directions for further development of QM theory are proposed.}
}
@article{DAVEY1997470,
title = {Predicting the dynamic product heat load and weight loss during beef chilling using a multi-region finite difference approach},
journal = {International Journal of Refrigeration},
volume = {20},
number = {7},
pages = {470-482},
year = {1997},
issn = {0140-7007},
doi = {https://doi.org/10.1016/S0140-7007(97)00048-0},
url = {https://www.sciencedirect.com/science/article/pii/S0140700797000480},
author = {L.M Davey and Q.T Pham},
keywords = {chilling, beef, heat flux, modelling, mass loss, réfrigération, boeuf, flux thermique, modélisation, perte de masse},
abstract = {A model for predicting the dynamic product heat load and weight loss during beef chilling has been developed using the finite difference method, in which the irregular beef geometry is approximated by a combination of seven cylinders and slabs. The model was tested against data from 55 industrial beef chilling trials covering a wide range of carcass size, fatness and chilling conditions. The predicted heat removed during the first 2 h in the model was on average 12.6% higher than the experimental value. The predicted weight loss after 20 h was on average 0.0194 kg (0.00046%) higher than the experimental value. Improvements in accuracy would probably have arisen if slaughter floor and chiller conditions had been more accurately known. The model allows for time-variable chiller conditions, making it widely applicable to meat industrv applications.
Résumé
On met au point un modèle de prévision de la charge thermique et de la perte de masse en régime variable lors de la réfrigération de boeuf à l'aide d'une méthode par différences finies, la géométrie du boeuf étant approchée par une combinaison de sept cylinders ou plaques. On a essayé ce modèle par rapport aux données provenant de sept essais sur le boeuf dans l'industrie, avec une large gamme de tailles de carcasses, de teneurs en graisse et de conditons de refroidissement. La chaleur éliminée lors des deux premières heures prévue par le modèle était en moyenne supérieure à la valeur expirimentale de 12,6%. La perte de masse prévue après 20 heures était d'environ 0,0194 kg (0,00046%) supérieure à la valeur expérimentale. La précision aurait probablement encore augmenté si 1'on avait mieux connu les conditions du sol de la salle d'abattage et celles du frigorifère. Ce modèle permet de tenir compte de variations dans l'apport de froid en fonction du temps, ce qui le rend largement applicable dans l'industrie de la viande}
}
@article{PETER1977110,
title = {Quasi-fission and other strongly damped collisions between 63Cu ions and 197Au nuclei},
journal = {Nuclear Physics A},
volume = {279},
number = {1},
pages = {110-124},
year = {1977},
issn = {0375-9474},
doi = {https://doi.org/10.1016/0375-9474(77)90424-9},
url = {https://www.sciencedirect.com/science/article/pii/0375947477904249},
author = {J. Péter and C. Ngô and F. Plasil and B. Tamain and M. Berlanger and F. Hanappe},
keywords = {Nuclear Reactions},
abstract = {The interaction of 63Cu ions with 197Au nuclei have been studied experimentally at incident energies of 365 and 443 MeV (1.1 and 1.4 times the Coulomb barrier). Mass and kinetic energy distributions of reaction products have been measured at several angles. Near the grazing angle, a continuous transition was found from elastic events to partially damped (PD) events, and to fully damped events (quasi-fission, QF). Away from the grazing angle a clean separation between elastic and QF events was observed. Events that may be due to fission following fusion (CF) were also obtained. Results are discussed in terms of decomposition into PD, QF, and CF components. The QF kinetic energy is independent of the incident energy (implying full damping of the initial relative motion). It is lower than the Coulomb barrier and close to the kinetic energies from the fission of similar systems. The angular distribution is peaked somewhat forward of the grazing angle for low mass transfers. For large mass transfers the yield increases slowly with decreasing angle. At 443 MeV a large contribution from negative angles is present. σQF accounts for more than 65 % of the reaction cross section σR at 443 MeV and for more than 50 % at 365 MeV. The upper limit on CF is about 10 % of σR, and σPDis of the order of 25 % of σR.}
}
@article{RAMAN1995187,
title = {Simultaneous determination of product attributes and prices, and production processes in product-line design},
journal = {Journal of Operations Management},
volume = {12},
number = {3},
pages = {187-204},
year = {1995},
issn = {0272-6963},
doi = {https://doi.org/10.1016/0272-6963(95)00013-I},
url = {https://www.sciencedirect.com/science/article/pii/027269639500013I},
author = {Narayan Raman and Dilip Chhajed},
abstract = {Global competition, rapid changes in technology, and market fragmentation have resulted in shorter product life cycles. In order to remain viable, it is increasingly important for firms to introduce new products frequently. Product design is a complex process that involves coordination of activities among several functional disciplines within the company as well as the customers and the suppliers. Traditionally, the information flow among the various product development stages has been sequential. However, there is increasing evidence to suggest that an integrated approach that considers several stages simultaneously may be superior. This paper provides a decision support tool for implementing such an integrated approach. On the basis of given customer preferences, the paper presents a model for determining the number of new products to be introduced, the exact specifications of these products, and the production processes for efficiently delivering these specifications. These decisions are made in an integrated manner by simultaneously considering the interaction among the various choice variables. A decomposition-based solution procedure is developed that iterates between the product design and process selection decisions while maintaining an effective link between them. In addition to understanding the economic value of adopting the integrated approach to product design, the paper discusses how the proposed model can be used effectively to perform sensitivity analysis with respect to some of the important decision variables.}
}
@article{LARSEN1990265,
title = {Proof systems for satisfiability in Hennessy-Milner Logic with recursion},
journal = {Theoretical Computer Science},
volume = {72},
number = {2},
pages = {265-288},
year = {1990},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(90)90038-J},
url = {https://www.sciencedirect.com/science/article/pii/030439759090038J},
author = {Kim G. Larsen},
abstract = {An extension of Hennessy-Milner Logic with recursion is presented. A recursively specified formula will have two standard interpretations: a minimal one and a maximal one. Minimal interpretations of formulas are useful for expressing liveness properties of processes, whereas maximal interpretations are useful for expressing safety properties. We present sound and complete proof systems for both interpretations for when a process satisfies a (possibly recursive) formula. The rules of the proof systems consist of an introduction rule for each possible structure of a formula and are intended to extend the work of Stirling and Winskel. Moreover the proof systems may be presented directly in PROLOG to yield a decision procedure for verifying when a finite-state process satisfies a specification given as a (possibly recursive) formula.}
}
@article{GOREE1966835,
title = {Pressure dependence of electrical conductivity of metals at low temperatures},
journal = {Journal of Physics and Chemistry of Solids},
volume = {27},
number = {5},
pages = {835-848},
year = {1966},
issn = {0022-3697},
doi = {https://doi.org/10.1016/0022-3697(66)90257-5},
url = {https://www.sciencedirect.com/science/article/pii/0022369766902575},
author = {W.S. Goree and T.A. Scott},
abstract = {Using a large high pressure helium gas facility, the electrical resistance of high purity wires of Au, Ag, In and Sn has been measured as a function of hydrostatic pressure up to 6 kb at selected temperatures between 4.2°K and 297°K. The lattice vibration and impurity contributions to the total resistivity pressure coefficient (1ρ)(dρdP) are separated and the lattice contribution is analyzed in terms of Bloch-Gruneisen theory and recent more general considerations. In a companion experiment the electrical resistance of Au, Ag, Mo, Ta and W was measured at 4.2°K as a function of pressure up to 8 kb using piston-cylinder apparatus with solid helium as pressure transmitter. For the Au sample a direct comparison is obtained between the piston-cylinder technique and precise hydrostatic measurements with the gas system. Data on pressure coefficients from all the experiments are presented in tabular form for comparison.}
}
@article{THOMAS1974287,
title = {Engineering development of hyperfiltration with dynamic membranes Part I. Process and module development},
journal = {Desalination},
volume = {15},
number = {3},
pages = {287-306},
year = {1974},
issn = {0011-9164},
doi = {https://doi.org/10.1016/S0011-9164(00)82034-2},
url = {https://www.sciencedirect.com/science/article/pii/S0011916400820342},
author = {David G. Thomas and William R. Mixon},
abstract = {Techniques were developed for precoating ceramic tubes with a 0.006-in. layer of fine particle size ZrO2 powder; dynamic membranes formed on the precoated porous surfaces possessed fluxes of 95 to 100 gal/ft2·day and rejections of 85 to 90% for 0.05 M NaCl compared with values of 20 gal/ft2·day and 40 to 60% obtained with nonprecoated tubes. These ceramic tubes were then incorporated in a seven-tube bundle with a total area of 6 ft2. A module consisted of two of these bundles fitted into a pressure housing fabricated from standard 2-in. pipe; this module then possessed a flux density of 4453 gal/day per cubic ft. compared with values of 1350 and 3000 gal/day per cubic ft for hollow fine fiber and spiral wrap modules, respectively (1). Since 1971 the flux density for hollow fine fibers has been 13,000–18,000. Similarly, the flux of membranes utilized in spiral wound or tubular systems has also increased very significantly, but not by an order of magnitude. The procedure developed for forming dynamic membranes on the ceramic tube modules consists of the following steps: 1.Adjust the pH of the 0.05 M NaCl feed solution to pH = 4 and add sufficient hydrous zirconium oxide to give a concentration of 50 mg/liter.2.Within one-half to one hour after introduction of the feed to the system at a pressure of 1000 psig and a velocity of 30 ft/sec, either the flux will be of the order of 1000 gal/ft2·day or the rejection will be 35 %; whichever value occurs first is not critical. At that time adjust the pH of the flowing stream to 2 and add sufficient PAA to give a concentration of 50 mg/liter.3.Approximately one hour after addition of the PAA begin neutralization of the flowing stream with NaOH solution. The pH should be increased in steps over an interval of one to two hours until the circulating stream is near neutral. At this time the dynamic membrane should have a rejection of 85 to 90% and a flux of 95 to 100 gal/ft2·day when the feed is 0.05 M NaCl. The velocity can then be reduced to 15 ft/sec with little loss in flux or rejection.}
}
@article{FELDERHOF1965295,
title = {On fluctuations and coherence of radiation in classical and semi-classical plasmas},
journal = {Physica},
volume = {31},
number = {3},
pages = {295-316},
year = {1965},
issn = {0031-8914},
doi = {https://doi.org/10.1016/0031-8914(65)90035-2},
url = {https://www.sciencedirect.com/science/article/pii/0031891465900352},
author = {B.U. Felderhof},
abstract = {The theory of thermal equilibrium fluctuations in plasmas, developed in a previous paper1), is extended to include radiation. Expressions are derived for the correlation tensors of the electromagnetic field.}
}
@article{GUKOV2017583,
title = {RG flows and bifurcations},
journal = {Nuclear Physics B},
volume = {919},
pages = {583-638},
year = {2017},
issn = {0550-3213},
doi = {https://doi.org/10.1016/j.nuclphysb.2017.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0550321317301177},
author = {Sergei Gukov},
abstract = {Interpreting RG flows as dynamical systems in the space of couplings we produce a variety of constraints, global (topological) as well as local. These constraints, in turn, rule out some of the proposed RG flows and also predict new phases and fixed points, surprisingly, even in familiar theories such as O(N) model, QED3, or QCD4.}
}
@article{LENTON1974313,
title = {3 - Other Disorders of Ovulation},
journal = {Clinics in Obstetrics and Gynaecology},
volume = {1},
number = {2},
pages = {313-344},
year = {1974},
issn = {0306-3356},
doi = {https://doi.org/10.1016/S0306-3356(21)00267-3},
url = {https://www.sciencedirect.com/science/article/pii/S0306335621002673},
author = {Elizabeth Lenton and I.D. Cooke},
abstract = {SUMMARY
The normal menstrual cycle is a complex and delicate balance of a number of hormones which all play different roles in the development and release of an ovum and the subsequent implantation and maintainance of the blastocyst. Control of this hormonal milieu is effected through a number of 'feedback’ mechanisms which vary from positive to negative in action at different stages of the cycle. Control of the output of gonadotrophins is mediated both through the hypothalamus (via LHRH) and by the action of circulating ovarian steroids directly on the pituitary itself. The relative importance of these two levels of control undoubtedly differs for each of the two pituitary hormones. Both FSH and LH are known to be secreted episodically and it is now thought that the amplitude and frequency of these pulsatile bursts of secretion are important factors in the differential action of these peptides on the ovary at different stages in the menstrual cycle. LH appears to have a much more fluctuant and variable secretion profile than FSH, which fits well with its effects in the follicular, midcycle and luteal phases respectively. With this background of the function of a normal cycle, the defective cycle was then defined as a regular one and where conception repeatedly fails to occur in the absence of other disease or apparent abnormality. Since little is actually known about the endocrinological relationships in abnormal cycles, a number of theoretically possible causes of defective ovulation were postulated. Menstrual cycles classed as being ovulatory (usually by BBT) but that are infertile can be sub-divided into three groups, namely defective follicular phase (DFP), defective mid-cycle surge (DMCS) and defective luteal phase (DLP) indicating those parts of the cycle in which the abnormality originates. It is stressed that because of the complex cyclic events occurring, a defect in one phase will frequently affect the next; thus a DLP, although it can occur spontaneously, is most often the sequel of a DFP, and these abnormal events may be perpetuated. The minimal clinical investigations in this group of patients is similar to those with anovulatory cycles, as is the treatment. Basically therapy consists of either clomiphene or HMG, followed sequentially by HCG.}
}
@article{BIGI198741,
title = {CP violation in heavy flavor decays: Predictions and search strategies},
journal = {Nuclear Physics B},
volume = {281},
number = {1},
pages = {41-71},
year = {1987},
issn = {0550-3213},
doi = {https://doi.org/10.1016/0550-3213(87)90246-X},
url = {https://www.sciencedirect.com/science/article/pii/055032138790246X},
author = {I.I. Bigi and A.I. Sanda},
abstract = {We present a comprehensive analysis of the phenomenology relevant for CP violation in exclusive B and D decays. Some of the CP asymmetries can be calculated rather reliably in the standard model, while others contain large uncertainties. We point out that studies of inclusive decays will have to deal with partial cancellations occurring between different exclusive channels. None of the measurements will be easy. Yet a realistic evaluation of the promise the various searches hold out cannot be given at present; first, one has to build a data base on the production and decay properties of heavy flavor decays. We try to identify the required information.}
}
@article{VELINOV1988205,
title = {An algebraic structure for derivations in rewriting systems},
journal = {Theoretical Computer Science},
volume = {57},
number = {2},
pages = {205-224},
year = {1988},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(88)90039-4},
url = {https://www.sciencedirect.com/science/article/pii/0304397588900394},
author = {Yury Velinov},
abstract = {In the present paper a uniform description of the algebraic properties of derivations in a rewriting system, and of their syntax and semantics is proposed on the base of a polycategory structure. Similarity relations between derivations are studied on syntax and semantic levels. Several canonical derivation forms are described.}
}
@article{ELMOSELHY2013598,
title = {Hybrid lean–agile manufacturing system technical facet, in automotive sector},
journal = {Journal of Manufacturing Systems},
volume = {32},
number = {4},
pages = {598-619},
year = {2013},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2013.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612513000782},
author = {Salah A.M. Elmoselhy},
keywords = {Lean manufacturing, Agile manufacturing, Value chain, Focused factory, E-manufacturing, System dynamics},
abstract = {In the automotive sector, planners have a difficult balancing act. They benefit from commonality of vehicle parts, yet they must meet more niche demands. The challenge is to strike a balance between these extremes in a cost-effective way without compromising quality. Lean strategies could increase competitiveness and profitability by reducing manufacturing costs. Concurrently, agile strategies could enable enterprises to cope with fluctuations. A hybrid lean–agile approach can be an optimal strategic blend for a manufacturing enterprise to meet this challenge. Flexible focused factory, globalized fractal E-manufacturing, innovative value chain strategies, and designing dynamic manufacturing strategies are the four technical pillars of the proposed hybrid lean–agile manufacturing system technical facet. The study shows that hybridizing the lean and agile systems together is technically valid and can be implemented in an industrial setting. It shows how strategically a hybrid lean–agile system can be implemented. It also shows that about one third of the variation in successfully dealing with the sources of competitive advantage in automotive industry can be explained by adopting the technical facet of the hybrid lean–agile manufacturing system.}
}
@article{LEUTWYLER1979327,
title = {Local spin−12 wave equations and harmonic confinement},
journal = {Nuclear Physics B},
volume = {157},
number = {2},
pages = {327-364},
year = {1979},
issn = {0550-3213},
doi = {https://doi.org/10.1016/0550-3213(79)90509-1},
url = {https://www.sciencedirect.com/science/article/pii/0550321379905091},
author = {H. Leutwyler and J. Stern},
abstract = {We propose that the long-range forces confining the qq̄ system may be described by a pair of local covariant wave equations. It is proven that the integrability conditions of this pair determine the interaction essentially uniquely. Within a rather general class of wave equations there are only two charge conjugation symmetric solutions of the integrability conditions: (i) free quarks, (ii) harmonically confined quarks. Some possible generalizations that may be of interest in connection with the description of mesons containing quarks of unequal mass are discussed.}
}
@article{KYRS1965245,
title = {The method of concentration-dependent distribution in the quantitative use of radioisotopes: Theoretical calibration curves and comparison to the “substoichiometric principle”},
journal = {Analytica Chimica Acta},
volume = {33},
pages = {245-256},
year = {1965},
issn = {0003-2670},
doi = {https://doi.org/10.1016/S0003-2670(01)84887-X},
url = {https://www.sciencedirect.com/science/article/pii/S000326700184887X},
author = {Miroslav Kyrš},
abstract = {The method is based on the utilization of a calibration curve which shows the dependence of the distribution ratio in a two-phase system containing the substance to be determined or a substance reacting with it, on the total concentration of the substance to be determined. The relationship of the proposed method to radiometric titration and to the “substoichiometric principle” in isotopic dilution is discussed. Formulae for the theoretical calibration curves in 4 systems are derived: sorption conforming to the Langmuir isotherm or to the Freundlich isotherm, extraction with a constant quantity of an extracting agent, and sorption or extraction in the presence of a constant quantity of a chelating agent. Theoretical sensitivities are given.
Résumé
La méthode proposée est basée sur l'utilisation d'une courbe de calibrage, montrant le rapport de coefficient de partage dans un système à deux phases, lors de l'utilisation de radioisotopes en analyse quantitative. On examine la relation de cette méthode avec un titrage radiométrique et avec “le principe substoéchiométrique” en dilution isotopique.
Zusammenfassung
Es wird eine Methode der konzentrationsabhängigen Verteilung beschrieben, wie sie bei der Anwendung von Radioisotopen bei der quantitativen Analyse verwendet wird. Die Methode benutzt eine Eichkurve, die die Abhängigkeit des Verteilungsverhältnisses in einem 2-Phasen-System, das die zu bestimmende Substanz oder eine andere, die mit ihr reagiert, enthält, von der Totalkonzentration der zu bestimmenden Substanz zeigt. Die Beziehung der vorgeschlagenen Methode zur radiometrischen Titration und zu dem “substöchiometrischen” Prinzip bei der Isotopenverdünnung wird diskutiert. Es werden Formeln für die theoretischen Eichkurven von 4 Systemen abgeleitet: die Sorption, die sich nach der LangmuirIsotherme oder nach der Freundlich-Isotherme richtet, die Extraktion mit einer konstanten Menge eines extrahierenden Reagenzes und die Sorption oder Extraktion in Gegenwart einer konstanten Menge eines Chelatbildners. Theoretische Empfindlichkeiten werden angegeben.}
}
@article{UEDA2009681,
title = {Value creation and decision-making in sustainable society},
journal = {CIRP Annals},
volume = {58},
number = {2},
pages = {681-700},
year = {2009},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2009.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0007850609001772},
author = {K. Ueda and T. Takenaka and J. Váncza and L. Monostori},
keywords = {Emergent synthesis, Sustainability, Value creation},
abstract = {Manufacturing exists to create value. However, historically, discussion of economic issues in manufacturing primarily emphasizes cost. It is becoming more difficult to understand and control values of products and services in response to rapid globalization and networking. This paper presents a discussion of the nature of value considering a history of axiology, design problems of artifacts, social dilemmas, network externalities, and sustainability. Promising academic methodologies are presented herein with emphasis on transdisciplinary and synthetic approaches. Value creation models based on Emergent Synthesis and co-creative decision-making are presented. This paper involves some important study examples of service and production toward sustainable value creation in society.}
}
@article{SARWAR2024102369,
title = {Design concept evaluation based on cloud rough model and modified AHP-VIKOR: An application to lithography tool manufacturing process},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102369},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102369},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400017X},
author = {Musavarah Sarwar and Faiqa Bashir},
keywords = {Design concept evaluation, Cloud rough numbers, Cloud rough AHP, Cloud rough VIKOR, Lithography},
abstract = {Design concept evaluation is a wide domain of research as the production process of new product development is mainly based on the evaluations of experts. As different types of uncertainties like vagueness, randomness, and diversity essentially exist in the evaluation information, the manipulation models that deal with just one type of uncertainty are not appropriate for ranking the design alternatives. The integration of multiple approaches into a single mathematical model to create an effective framework is more useful for uncertain information manipulation. This paper presents an innovative group decision-making approach to evaluate design concepts by integrating cloud rough numbers, analytic hierarchy process (AHP) and VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method to introduce a novel cloud rough AHP-VIKOR model. The concept of cloud rough numbers is utilized by fusing the merits of the cloud model theory and rough approximations in addressing randomness in experts’ judgments and intrapersonal uncertainty for handling consensus inconsistency. Some new modified algebraic operations are introduced to remove the errors in already existing operations of cloud rough numbers. The cloud rough AHP technique is introduced to compute weights of design criteria by computing the cloud rough numbers of linguistic values and their reciprocals. Based on cloud rough values of positive and negative ideals, the individual regret, group utility values and evaluation indices are determined. Using the distance of evaluation indices from minimized cloud rough value, the design alternatives are ranked using different formulae. The significance of the proposed approach is illustrated with a real-world application in lithography tool manufacturing process. The out-performance and reliability of the proposed model is studied by a sensitivity analysis of different parameters in the method, and a comparison analysis with existing approaches.}
}
@article{TOMIYAMA2019727,
title = {Development capabilities for smart products},
journal = {CIRP Annals},
volume = {68},
number = {2},
pages = {727-750},
year = {2019},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0007850619301672},
author = {Tetsuo Tomiyama and Eric Lutters and Rainer Stark and Michael Abramovici},
keywords = {Design, Product development, Model-based systems engineering},
abstract = {Smart products supported by new step-changing technologies, such as Internet of Things and artificial intelligence, are now emerging in the market. Smart products are cyber physical systems with services through Internet connection. For example, smart vehicles equipped with advanced embedded intelligence are connected to other vehicles, people, and environment, and offer innovative data-driven services. Since smart products are software-intensive, data-driven, and service-conscious, their development clearly needs new capabilities underpinned by advanced tools, methods, and models. This paper reviews the status and trends of these emerging development technologies such as model-based systems engineering and digital twin.}
}
@article{COOPER1996465,
title = {Overhauling the new product process},
journal = {Industrial Marketing Management},
volume = {25},
number = {6},
pages = {465-482},
year = {1996},
issn = {0019-8501},
doi = {https://doi.org/10.1016/S0019-8501(96)00062-4},
url = {https://www.sciencedirect.com/science/article/pii/S0019850196000624},
author = {Robert G. Cooper},
abstract = {The three cornerstones of successful product development are process, strategy, and resources, according to the benchmarking study reported in this article. Of the three, having a high quality new product process had the strongest impact on business's new product performance. A high quality new product process meant: an emphasis on up-front homework; sharp, early product definition; the voice of the customer evident throughout; tough go/kill decision points; a focus on quality of execution; and a thorough yet flexible process. The research results point strongly to a need to overhaul firms' new product processes—from idea to launch—to incorporate these and other key success drivers, such as the quest for real product superiority, and the need for true cross-functional teams. The goals of an effective new product process—that is, the specifications or key elements of a high quality process—are outlined, a vital starting point to any process reengineering exercise. The article ends with a quick look at a third generation stage-gate or new product process, together with some tips and hints on how to proceed to overhaul your company's new product process.}
}
@article{GOVINDAN20149,
title = {Two-echelon multiple-vehicle location–routing problem with time windows for optimization of sustainable supply chain network of perishable food},
journal = {International Journal of Production Economics},
volume = {152},
pages = {9-28},
year = {2014},
note = {Sustainable Food Supply Chain Management},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2013.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0925527313005872},
author = {K. Govindan and A. Jafarian and R. Khodaverdi and K. Devika},
keywords = {Food supply chain, Perishable foods, Sustainability, Sustainable supply chain design, Two-echelon location–routing problem, Greenhouse gases emissions, Robust multi-objective metaheuristic},
abstract = {Increasing environmental, legislative, and social concerns are forcing companies to take a fresh view of the impact of supply chain operations on environment and society when designing a sustainable supply chain. A challenging task in today's food industry is distributing high quality perishable foods throughout the food supply chain. This paper proposes a multi-objective optimization model by integrating sustainability in decision-making, on distribution in a perishable food supply chain network (SCN). It introduces a two-echelon location–routing problem with time-windows (2E-LRPTW) for sustainable SCN design and optimizing economical and environmental objectives in a perishable food SCN. The goal of 2E-LRPTW is to determine the number and location facilities and to optimize the amount of products delivered to lower stages and routes at each level. It also aims to reduce costs caused by carbon footprint and greenhouse gas emissions throughout the network. The proposed method includes a novel multi-objective hybrid approach called MHPV, a hybrid of two known multi-objective algorithms: namely, multi-objective particle swarm optimization (MOPSO) and adapted multi-objective variable neighborhood search (AMOVNS). MHPV features two strategies for leader selection procedures (LSP), (i.e. Grids) and crowding distance is compared to common genetic algorithms based on metaheuristics (i.e. MOGA, NRGA and NSGA-II). Results indicate that the hybrid approach achieves better solutions compared to others, and that crowding distance method for LSP outperforms the former Grids method.}
}
@article{GUNASEKARAN2009319,
title = {Modeling and analysis of build-to-order supply chains},
journal = {European Journal of Operational Research},
volume = {195},
number = {2},
pages = {319-334},
year = {2009},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2008.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221708003366},
author = {Angappa Gunasekaran and Eric W.T. Ngai},
keywords = {BTO/MTO, Supply chain, Modeling, Review, Future research},
abstract = {The build-to-order supply chain (BTO-SC) or make-to-order (MTO) system has received a great deal of attention in recent years because of the success of high-tech companies such as Dell, BMW, Compaq, and Gateway. Some auto companies have also implemented BTO-SC. Quite a few research articles have been written on BTO-SC and MTO. However, those that explicitly address the problems of BTO-SCM with modeling are rather limited in number. Considering the growing importance of more informed and timely decision making in these areas, there is a need to encourage further research on the modeling and analysis of global outsourcing, optimization between product variants and the cost of production, the point of differentiation along the production/assembly process, the selection of suppliers, logistics costs, and customer relationship management. Traditional operations research models have been used to solve supply chain management problems. Considering the importance of BTO or MTO, an attempt has been made to review the selected literature on the modeling and analysis of BTO-SC with the objectives of providing assistance to and motivating both researchers and practitioners to design, develop, and manage BTO-SC effectively; and suggesting some future research directions on BTO supply chain management (BTO-SCM). The literature available on BTO-SCM has been classified based on the nature of the decision-making areas and then sub-classified to focus on solving problems with modeling and analysis. We have focused mostly on the modeling aspect of the BTO-SC, but have not extended our efforts to empirical research. We have developed a unified framework for modeling and analyzing BTO-SCM and suggest some future research directions.}
}
@article{YALCIN2022121193,
title = {The use of multi-criteria decision-making methods in business analytics: A comprehensive literature review},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121193},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121193},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006260},
author = {Ahmet Selcuk Yalcin and Huseyin Selcuk Kilic and Dursun Delen},
keywords = {Business analytics, Decision support, Multi-criteria decision making (MCDM), Multi-attribute decision-making (MADM), Multi-objective decision-making (MODM)},
abstract = {Business analytics (BA) systems are considered significant investments for enterprises because they have the potential to considerably improve firms’ performance. With the value offered by BA, companies are able to discover the hidden information in the data, improve decision-making processes, and support strategic planning. On the other hand, because there are multiple criteria and multiple alternatives involved in most decision-making situations, multi-criteria decision-making (MCDM) methods play an important role in BA practices. Providing inputs to the components of descriptive or predictive analytics or being used as a decision-making tool for evaluating the alternatives within prescriptive analytics exemplify the roles. Therefore, the use of hidden information discovered by business analytics and the need for utilizing the right MCDM method for optimal decision-making made these two concepts inseparable. In this paper, in order to review the use of MCDM methods in BA, the subject of BA is investigated from a taxonomical perspective (descriptive, predictive, and prescriptive), and its connection with MCDM techniques is revealed. Similarly, MCDM methods are studied using two main categories, multi-attribute decision making (MADM) and multi-objective decision making (MODM) methods. Furthermore, tabular and graphical analyses are also performed within the proposed review methodology. To the best of our knowledge, this review is the first attempt that holistically considers the use of MCDM methods in BA.}
}
@article{KAKATI2024122724,
title = {Analysis and application of rectified complex t-spherical fuzzy Dombi-Choquet integral operators for diabetic retinopathy detection through fundus images},
journal = {Expert Systems with Applications},
volume = {243},
pages = {122724},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122724},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423032268},
author = {Pankaj Kakati and Shio Gai Quek and Ganeshsree Selvachandran and Tapan Senapati and Guiyun Chen},
keywords = {Rectified complex -spherical fuzzy sets, Dombi-Choquet integral operator, Complex fuzzy set, Fuzzy set, Fundus image, Diabetic retinopathy detection},
abstract = {This paper proposes a rectified complex spherical fuzzy set (rCTSFS) model that enables the phase term of a complex number to function truthfully to its inherent meaning of representing directions, phases, or color hues. In addition, this paper proposes the score and accuracy functions for rectified complex spherical fuzzy numbers (rCTSFn), which allows the three types of membership degrees of an rCTSFn to fulfill human judgment/intuition. The proposed rCTSFS model proves to be a productive extension of the complex spherical fuzzy set (CSFS), complex fuzzy set (CFS), and spherical fuzzy set (SFS) models. On the other hand, Dombi t-norms prove more flexible and comprehensive than some of the other families of triangular norms, such as the algebraic t-norms and the Einstein t-norms, due to the presence of a parameter γ. The parameter γ determines the amount of aggressiveness at estimating the maximum and the minimum of a population based on a sample obtained. Therefore, this paper proposes two Dombi-Choquet integral operators, namely, the rectified complex t-spherical fuzzy arithmetic Dombi-Choquet integral (rCTSFAγ,wλ) operator and the rectified complex t-spherical fuzzy geometric Dombi-Choquet integral (rCTSFGγ,wλ) operator. A multi-criteria decision making (abbr. MCDM) algorithm utilizing the two Dombi-Choquet integral operators is innovated. The proposed Dombi-Choquet MCDM algorithm for the rCTSFS model is applied to an MCDM problem related to diabetic retinopathy detection on five real-life fundus images of different severity levels taken from the Messidor2 dataset. Our newly proposed algorithm proves to be the only algorithm that yields the correct diagnostic results that match the hard truth. On the other hand, none of the 50 algorithms observed among recent works in literature can produce the correct diagnostic results, even after lending the fuzzification procedure innovated in this work to them.}
}
@article{FOROOZESH2023100440,
title = {A hybrid decision-making method using robust programming and interval-valued fuzzy sets for sustainable-resilient supply chain network design considering circular economy and technology levels},
journal = {Journal of Industrial Information Integration},
volume = {33},
pages = {100440},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100440},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X23000134},
author = {N. Foroozesh and B. Karimi and S.M. Mousavi and M. Mojtahedi},
keywords = {Sustainable-resilient supply chain network design, Circular economy, Interval-valued fuzzy-sets, Compromise decision-making method, Interval-valued fuzzy-robust programming, AUGMECON2 method},
abstract = {This study introduces a new three-stage optimization approach with a circular economy perspective for sustainable-resilient supply chain network design for perishable products. The proposed model specifies the number of facilities and the number of products flowing within the supply chain in case of disruption. The three contributions of the mathematical model are considering product lifetime, monitoring financial resources, and selecting technology levels. It incorporates suppliers’ green image and circular economy rating in the supply chain network structure. Epistemic uncertainty is considered in the optimization model to deal with the unknown capacity, cost, and demand. The study includes three main stages. In the first stage, to determine suppliers' green image and circular economy rating, a new interval-valued fuzzy (IVF)-compromise decision-making method is presented based on possibilistic mean and standard deviation evaluations. In the second stage a new multi-objective mathematical model is proposed to reduce total costs, reduce environmental impacts, and increase social sustainability. To deal with uncertainties in the mathematical model, a new IVF-robust solution approach is introduced. In the third stage, the solution is incorporated with the AUGMECON2 method to produce separate Pareto-optimal solutions, offering a hybrid of trade-offs between cost, emissions, and social responsibility. A case study in the food, dairy, and drink industry is presented to show how the suggested approach might be applied. Finally, several sensitivity analyses and comprehensive comparisons of the proposed approach with the literature were performed.}
}
@article{PENROSE199044,
title = {Thermodynamically consistent models of phase-field type for the kinetic of phase transitions},
journal = {Physica D: Nonlinear Phenomena},
volume = {43},
number = {1},
pages = {44-62},
year = {1990},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(90)90015-H},
url = {https://www.sciencedirect.com/science/article/pii/016727899090015H},
author = {Oliver Penrose and Paul C. Fife},
abstract = {A general framework is given for the phenomenological kinetics of phase transitions in which not only the order parameter but also the temperature may vary in time and space. Instead of a Ginzburg-Landau free energy functional, as used in formulating the Cahn-Hilliard equation, we use the analogous entropy functional. Model entropy functionals, and the kinetic equations resulting from them, are constructed for various cases: phase transitions with and without a critical point, and (in the former case) with or without a latent heat. The class considered is general enough to include the entropy functionals for the Ising model in mean-field approximation, the van der Waals fluid, and a simplified version of the density-functional theory of freezing. A case without critical point, for which the energy is conserved but the order parameter is not, provides a thermodynamically consistent derivation of the phase-field equations studied by Caginalp, Fix and others, and also leads in a natural way to the Lyapunov functional given by Langer for these equations; but the treatment also suggests that a modified version of the phase-field equations might provide a more realistic model of freezing.}
}
@article{DEVRIES196841,
title = {Double-layer charging in constant-current chronopotentiometry at a mercury-film electrode},
journal = {Journal of Electroanalytical Chemistry and Interfacial Electrochemistry},
volume = {19},
number = {1},
pages = {41-53},
year = {1968},
issn = {0022-0728},
doi = {https://doi.org/10.1016/S0022-0728(68)80188-3},
url = {https://www.sciencedirect.com/science/article/pii/S0022072868801883},
author = {W.T. {De Vries}},
abstract = {Summary
Constant-current chronopotentiograms of an amalgam-forming metal at a mercury-film electrode, distorted by double-layer charging, are calculated. The problem is formulated as a non-linear integral equation which can be evaluated numerically. The differential electrode double-layer capacity is assumed to be constant. Reduction and oxidation chronopotentiograms are considered and evaluation of results follows two main approaches: (i) a range of mercury-film thickness and transition time (combined into one parameter, h) is established in which the resulting E,t-curves can be treated in the same manner as those for semi-infinite diffusion (h=∞); (ii) methods are outlined by which distorted chronopotentiograms, for h→o, can be corrected, and the applicability of these methods for higher values of h is investigated.}
}
@article{PAKSOY20122822,
title = {Organizational strategy development in distribution channel management using fuzzy AHP and hierarchical fuzzy TOPSIS},
journal = {Expert Systems with Applications},
volume = {39},
number = {3},
pages = {2822-2841},
year = {2012},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2011.08.142},
url = {https://www.sciencedirect.com/science/article/pii/S0957417411012735},
author = {Turan Paksoy and Nimet Yapici Pehlivan and Cengiz Kahraman},
keywords = {Distribution channel management, Distribution organization, Fuzzy analytic hierarchy process, Hierarchical fuzzy TOPSIS, Extent analysis method},
abstract = {Distribution channel management not only consists of choosing distribution channels. In fact, probably the most difficult phase of the distribution management starts after this choice. Determining an appropriate organization strategy for distribution channel management is like a problem of concern to marketing practitioners and academics as well in this phase. In this study, the organization strategy of distribution channel management is developed using fuzzy analytic hierarchy process (FAHP) and hierarchical fuzzy TOPSIS (HFTOPSIS) for an edible-vegetable oils manufacturer firm operating in Turkey. The company distributes its products all over the country. Due to the complex structure of the distribution network, the company wants to decide the organization strategy to manage the distribution channels. In this paper, the methods of FAHP and HFTOPSIS for evaluating and selecting among the five organization strategy models for distribution channel management of vegetable oil manufacturer have been presented. The proposed models include determinants of distribution channel management for edible-vegetable oil industry; (i) customer profile, (ii) distributor reliability, (iii) the position of competitors in market, and (iv) managerial and financial perspective. Using FAHP and HFTOPSIS, hybrid based strategy (KBS), which has the greatest desirability index value after the evaluation among the five alternatives is found as the best choice. Thus, the case of the vegetable oil manufacturer company provides the researchers and practitioners to understand in a better way the importance of developing organization strategy in channel management from a practical point of view.}
}
@article{COHEN1997239,
title = {What makes teams work: Group effectiveness research from the shop floor to the executive suite},
journal = {Journal of Management},
volume = {23},
number = {3},
pages = {239-290},
year = {1997},
note = {A Special Issue Of The Journal Of Management},
issn = {0149-2063},
doi = {https://doi.org/10.1016/S0149-2063(97)90034-9},
url = {https://www.sciencedirect.com/science/article/pii/S0149206397900349},
author = {Susan G. Cohen and Diane E. Bailey},
abstract = {In this article, we summarize and review the research on teams and groups in organization settings published from January 1990 to April 1996. The article focuses on studies in which the dependent variables are concerned with various dimensions of effectiveness. A heuristic framework illustrating recent trends in the literature depicts team effectiveness as a function of task, group, and organization design factors, environmental factors, internal processes, external processes, and group psychosocial traits. The review discusses four types of teams: work, parallel, project, and management. We review research findings for each type of team organized by the categories in our heuristic framework. The article concludes by comparing the variables studied for the different types of teams, highlighting the progress that has been made, suggesting what still needs to be done, summarizing key learnings from the last six years, and suggesting areas for further research.}
}
@article{CHANDRASEGARAN2013204,
title = {The evolution, challenges, and future of knowledge representation in product design systems},
journal = {Computer-Aided Design},
volume = {45},
number = {2},
pages = {204-228},
year = {2013},
note = {Solid and Physical Modeling 2012},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2012.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010448512001741},
author = {Senthil K. Chandrasegaran and Karthik Ramani and Ram D. Sriram and Imré Horváth and Alain Bernard and Ramy F. Harik and Wei Gao},
keywords = {Knowledge representation, Knowledge capture, Knowledge management, Product design, Computational tools, Ontology, Systems engineering, Design rationale, Multidisciplinary modeling, Virtual reality, Collaborative engineering, Simulation},
abstract = {Product design is a highly involved, often ill-defined, complex and iterative process, and the needs and specifications of the required artifact get more refined only as the design process moves toward its goal. An effective computer support tool that helps the designer make better-informed decisions requires efficient knowledge representation schemes. In today’s world, there is a virtual explosion in the amount of raw data available to the designer, and knowledge representation is critical in order to sift through this data and make sense of it. In addition, the need to stay competitive has shrunk product development time through the use of simultaneous and collaborative design processes, which depend on effective transfer of knowledge between teams. Finally, the awareness that decisions made early in the design process have a higher impact in terms of energy, cost, and sustainability, has resulted in the need to project knowledge typically required in the later stages of design to the earlier stages. Research in design rationale systems, product families, systems engineering, and ontology engineering has sought to capture knowledge from earlier product design decisions, from the breakdown of product functions and associated physical features, and from customer requirements and feedback reports. VR (Virtual reality) systems and multidisciplinary modeling have enabled the simulation of scenarios in the manufacture, assembly, and use of the product. This has helped capture vital knowledge from these stages of the product life and use it in design validation and testing. While there have been considerable and significant developments in knowledge capture and representation in product design, it is useful to sometimes review our position in the area, study the evolution of research in product design, and from past and current trends, try and foresee future developments. The goal of this paper is thus to review both our understanding of the field and the support tools that exist for the purpose, and identify the trends and possible directions research can evolve in the future.}
}
@article{BUZA1996611,
title = {Heavy quark coefficient functions at asymptotic values Q2 ⪢ m2},
journal = {Nuclear Physics B},
volume = {472},
number = {3},
pages = {611-658},
year = {1996},
issn = {0550-3213},
doi = {https://doi.org/10.1016/0550-3213(96)00228-3},
url = {https://www.sciencedirect.com/science/article/pii/0550321396002283},
author = {M. Buza and Y. Matiounine and J. Smith and R. Migneron and W.L. {van Neerven}},
keywords = {Electroproduction, Charm, Structure function, Operator product},
abstract = {In this paper we present the analytic form of the heavy quark coefficient functions for deep inelastic lepton-hadron scattering in the kinematical regime Q2 ⪢ m2. Here Q2 and m2 stand for the masses squared of the virtual photon and heavy quark, respectively. The calculations have been performed up to next-to-leading order in the strong coupling constant αs using operator product expansion techniques. Apart from a check on earlier calculations, which however are only accessible via large computer programs, the asymptotic forms of the coefficient functions are useful for charm production at HERA when the condition Q2 ⪢ mc2 is satisfied. Furthermore, the analytical expressions can also be used when one applies the variable flavour number scheme up to next-to-leading order in αs.}
}
@article{CHEN199891,
title = {An integrated graphical user interface (GUI) for concurrent engineering design of mechanical parts},
journal = {Computer Integrated Manufacturing Systems},
volume = {11},
number = {1},
pages = {91-112},
year = {1998},
issn = {0951-5240},
doi = {https://doi.org/10.1016/S0951-5240(98)00016-0},
url = {https://www.sciencedirect.com/science/article/pii/S0951524098000160},
author = {Kun-Hur Chen and Shi-Jie (Gary) Chen and Li Lin and S.Wesley Changchien},
keywords = {concurrent engineering, graphical user interface (GUI), feature-based design, design for manufacturing (DFM), design for assembly (DFA), knowledge-based systems},
abstract = {Due to increasing competition in the manufacturing industry, the search for shorter product development and production cycles and lower cost has led to the emergence of concurrent engineering. Concurrent engineering is the practice whereby the design needs to simultaneously consider various downstream activities throughout the entire product life cycle, in addition to meeting the products' functions. This calls for an integrated design environment that will enable the engineers to evaluate multiple constraints from manufacturing, assembly, services, etc. at the design stage. This research develops a prototype for such an integrated graphical user interface (GUI), the Integrated Concurrent Engineering Design for Mechanical Parts (ICEDMP), in concurrent engineering. Using ICEDMP, the user can access product data from different domains of computerized tools in one software system and evaluate the design of mechanical products based on criteria of Design for Manufacturing (DFM) and Design for Assembly (DFA). Modules of ICEDMP include (1) a web-based on-line user's guide, (2) a part library, (3) a design guidelines checklist, (4) a part modeler linked to CAD (Pro/Engineer), (5) a part feature converter using Practical Extraction and Report Language (PERL), and (6) a knowledge-based design critique system. Parts created by Pro/Engineering CAD system are represented by features using the PERL feature converter. The design's consequential impact on manufacture and assembly is then evaluated by the knowledge-based design critique system implemented by CLIPS. Two design examples are presented to demonstrate the effectiveness of the ICEDMP system. Using ICEDMP, the user is able to evaluate the designs using DFM and DFA criteria and obtain suggestions to improve the design in one integrated software environment. This will result in fewer costly design changes and thus reduce product development time and production cost.}
}
@article{LIU2023120645,
title = {Managing multi-granular probabilistic linguistic information in large-scale group decision making: A personalized individual semantics-based consensus model},
journal = {Expert Systems with Applications},
volume = {230},
pages = {120645},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120645},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423011478},
author = {Yuanyuan Liu and Youlong Yang and Liqin Sun and An Huang},
keywords = {Probabilistic linguistic preference relation, Consensus reaching process, Large-scale group decision making, Multi-granular probabilistic linguistic information, Personalized individual semantics},
abstract = {The multi-granular probabilistic linguistic modeling allows decision makers to express cognitive information using multiple linguistic term sets based on their preferences. However, personalized individual semantics (PIS) can lead to different meanings of the same word within the linguistic context. To address this issue and manage consensus in large-scale group decision making, this study proposes a decision framework that employs multi-granular probabilistic linguistic preference relations (MGPLPRs). First, a transformation method is presented to unify different granularity levels of MGPLPRs, thus ensuring the consistency of granularity. Moreover, a consistency-driven optimization model is constructed to generate the numerical scales with PIS for different experts. Thereafter, a two-stage consensus reaching process (CRP) is developed, including both within-cluster and across-cluster CRP, to achieve group consensus. The experts’ original weights are derived from a social network, taking into account the trust relationships among them. A dynamic weighting mechanism is used to update the experts’ weights based on their contributions to group consensus, which better reflects the actual situation than fixed weights. The proposed method is exemplified through a case study of assessing and selecting campus surveillance measures for COVID-19. Finally, the effectiveness and robustness of the proposed framework are verified through comparative analysis and sensitivity analysis.}
}
@article{BRAATEN1985630,
title = {Torsion and geometrostasis in nonlinear sigma models},
journal = {Nuclear Physics B},
volume = {260},
number = {3},
pages = {630-688},
year = {1985},
issn = {0550-3213},
doi = {https://doi.org/10.1016/0550-3213(85)90053-7},
url = {https://www.sciencedirect.com/science/article/pii/0550321385900537},
author = {Eric Braaten and Thomas L. Curtright and Cosmas K. Zachos},
abstract = {We discuss some general effects produced by adding Wess-Zumino terms to the actions of nonlinear sigma models, an addition which may be made if the underlying field manifold has appropriate homological properties. We emphasize the geometrical aspects of such models, especially the role played by torsion on the field manifold. For general chiral models, we show explicitly that the torsion is simply the structure constant of the underlying Lie group, converted by vielbeine into an antisymmetric rank-three tensor acting on the field manifold. We also investigate in two dimensions the supersymmetric extensions on nonlinear sigma models with torsion, showing how the purely results carry over completely. We consider in some detail the renormalization effects produced by the Wess-Zumino terms using the background field method. In particular, we demonstrate to two-loop order the existence of geometrostasis, i.e. fixed points in the renormalized geometry of the field manifold due to parallelism.}
}
@article{STARR199089,
title = {The role of project management in a fast response organization},
journal = {Journal of Engineering and Technology Management},
volume = {7},
number = {2},
pages = {89-110},
year = {1990},
issn = {0923-4748},
doi = {https://doi.org/10.1016/0923-4748(90)90001-N},
url = {https://www.sciencedirect.com/science/article/pii/092347489090001N},
author = {Martin K. Starr},
keywords = {Project management, Simultaneous, Continuous, Incremental},
abstract = {In response to fundamental competitive changes in the 1990's, organizations are being redesigned to provide faster responses. Timeliness has become the major competitive objective, while low unit costs and high quality are crucial constraints. To understand the role that project management plays with respect to timeliness, it is useful to observe how two different organizational reaction levels characterize fast response organizations (FRO's). The first reaction level of FRO's is tactical and internal. The emphasis on process-orientation means a just-in-time focus for minimum work-in-process, coordinated vendor deliveries, near-zero defectives, fast repair, appropriate preventive maintenance, rapid changeovers, minimum lead times, and efforts to achieve continuous, value-added production of goods and services. The tactical aspects of FRO's have been covered in the literature. The second action level of FRO's is strategic. Strategies create markets and are technology-driven. The development of new products and processes requires project management methods that are competitive, i.e., fast to learn about and respond to market oppurtunities and emerging technological developments. Since the 1950's, traditional project management methods have emphasized project time reduction, as well as controls for time and costs. This paper explores two new project management approaches that are being used by industry to translate innovative ideas rapidly into better processes, goods and services. The first approach, as in rugby, has many players working together in a fully-coordinated team effort. The goal is to reduce the project development time. This is done by restructuring team assignments so that (within practical limits) everyone knows a great deal about the status of the entire project. Since many stages can be worked on at the same time, we call this simultaneous management of project stages. For this case, milestone triggers are generally not heeded, and there are broad team responsibilities for coordinating project stages. The second approach uses continuous project management, in contrast to single-product project management. With single-product development (such as producing one new car) there is a start-up time, and an ending time that signals the project's termination. Continuous project management, on the other hand, takes the form of an on-going effort to manage a stream of multiple new products (such as the development of a succession of new cars). Teams are permanently assigned to project development activities. Often the goals are targeted incremental improvements, but they also can be directed toward significant “breakthrough” versions to radically alter a previous product design. Since project teams are permanently engaged, there is no project termination, which is why this approach is often called “on- going project management”. The system has a memory for ideas with potential utility that had to be shelved the first time around because they did not fit the schedule and/or match the prior goals. The capacity to reexamine and learn from prior project steps that were taken is very important.}
}
@article{ZIEGLER1975145,
title = {Non-linearity in thermomechanics},
journal = {International Journal of Non-Linear Mechanics},
volume = {10},
number = {3},
pages = {145-154},
year = {1975},
issn = {0020-7462},
doi = {https://doi.org/10.1016/0020-7462(75)90032-3},
url = {https://www.sciencedirect.com/science/article/pii/0020746275900323},
author = {Hans Ziegler},
abstract = {The systems treated in classical thermodynamics are nongyroscopic. In such systems, the dissipative forces must be determined by the dissipation function. For elementary processes, this statement leads to the orthogonality principle proposed by the author in his earlier work.
Реферат
CиCteмы, paCCмatpиBaeмыe B клaCCичeCкoй tepмoмeчaникe, яBляюtCя нeжиpoCкoпными. B taкич CиCteмaч диCCипatиBныe Cилы дoлжны быtь oпpeдeлeны чeпeз диCCипatиBныe фУнкции. taкoe УtBepждeниe BeдetB CлУчae злeмeнtapнoгo пpoпeCCa к пpинципУ oпtoгoнaльнoCtи, кotopый был пpeдлoжeн aBtoпoм дaннoй paбotы B oлнoй из eгo пpeдыдУщич Ctateй.}
}
@article{KOCH201964,
title = {On the refinement of spreadsheet smells by means of structure information},
journal = {Journal of Systems and Software},
volume = {147},
pages = {64-85},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.09.092},
url = {https://www.sciencedirect.com/science/article/pii/S016412121830219X},
author = {Patrick Koch and Birgit Hofer and Franz Wotawa},
keywords = {Spreadsheets, Code smells, Static analysis},
abstract = {Spreadsheet users are often unaware of the risks imposed by poorly designed spreadsheets. One way to assess spreadsheet quality is to detect smells which attempt to identify parts of spreadsheets that are hard to comprehend or maintain and which are more likely to be the root source of bugs. Unfortunately, current spreadsheet smell detection techniques suffer from a number of drawbacks that lead to incorrect or redundant smell reports. For example, the same quality issue is often reported for every copy of a cell, which may overwhelm users. To deal with these issues, we propose to refine spreadsheet smells by exploiting inferred structural information for smell detection. We therefore first provide a detailed description of our static analysis approach to infer clusters and blocks of related cells. We then elaborate on how to improve existing smells by providing three example refinements of existing smells that incorporate information about cell groups and computation blocks. Furthermore, we propose three novel smell detection techniques that make use of the inferred spreadsheet structures. Empirical evaluation of the proposed techniques suggests that the refinements successfully reduce the number of incorrectly and redundantly reported smells, and novel deficits are revealed by the newly introduced smells.}
}
@article{LIU2020209,
title = {Multiattribute decision method for comprehensive logistics distribution center location selection based on 2-dimensional linguistic information},
journal = {Information Sciences},
volume = {538},
pages = {209-244},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.05.131},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520305533},
author = {Peide Liu and Ying Li},
keywords = {2-Dimensional linguistic information, Partitioned Maclaurin symmetric mean, Multiattribute group decision-making, Logistics distribution center location selection},
abstract = {The comprehensive logistics distribution center location selection (CLDCLS) problem is a multiattribute group decision-making (MAGDM) problem in which multiple commodity preference weights are considered. To better describe the preference information and expert evaluation information, this paper utilizes 2-dimensional linguistic (2DL) information to express the preference information of various commodities and the expert evaluation, which can represent not only the evaluation information of experts but also the reliability of the evaluation information. Additionally, for solving the CLDCLS problem, this paper puts forward improved operational rules a score function, a distance formula and a correlation coefficient measure. Based on the 2DL information and the improved operational rules, we propose a 2-dimensional linguistic similarity-degree-based clustering analysis method, the 2-dimensional linguistic partitioned Maclaurin symmetric mean (2DLPMSM) operator, and the 2-dimensional linguistic weighted partitioned Maclaurin symmetric mean (2DLWPMSM) operator. The corresponding properties and special cases are demonstrated. By using these proposed methods, this paper constructs a MAGDM solution framework for the CLDCLS problem. A practical case of the CLDCLS problem is presented to demonstrate the effectiveness, rationality, robustness and superior performance of the proposed method.}
}
@article{EARLY19781215,
title = {Hydrogen diffusion in palladium by galvanostatic charging},
journal = {Acta Metallurgica},
volume = {26},
number = {8},
pages = {1215-1223},
year = {1978},
issn = {0001-6160},
doi = {https://doi.org/10.1016/0001-6160(78)90005-6},
url = {https://www.sciencedirect.com/science/article/pii/0001616078900056},
author = {James G Early},
abstract = {The diffusion of hydrogen in α-palladium at ambient temperature has been studied by a galvanostatic technique. Single transient and multiple transient hydrogen charging experiments were conducted on specimens over a range of charging currents and specimen thicknesses. The mathematical description of multiple transient charging is developed for the galvanostatic technique from the general solution for diffusion. The diffusion coefficient at 23°C for hydrogen in α-palladium was determined to be (3.4 ± 0.2) × 10−7cm2/s in excellent agreement with results from Gorsky-effect measurements. The results demonstrate that bulk hydrogen diffusion is the rate controlling process, and the hydrogen flux boundary conditions assumed in the mathematical analyses were satisfied by the galvanostatic technique.
Résumé
On a étudié par une technique galvanostatique la diffusion de l'hydrogène dans le palladium a à la température ambiante. On a effectue des expériences de charge transitoire simple ou multiple d'hydrogène dans des échantillons, pour divers courants de charge et diverses épaisseurs d'échantillons. On développe la description mathématique de la charge multiple transitoire, pour la technique galvanostatique à partir de la solution générale de la diffusion. Le coefficient de diffusion de l'hydrogène dans le palladium α à 23°C vaut (3,4 ± 0,2) × 10−7cm2/s. ce qui est en excellent accord avec les résultats des mesures de l'effet Gorsky. Ces résultats démontrent que c'est la diffusion en volume de l'hydrogène qui est le processus contrôlant la vitesse, et que les conditions aux limites du flux d'hydrogène utilisées dans les analyses mathématiques sont satisfaites par la technique galvanostatique.
Zusammenfassung
Mit einer galvanostatischen Methode wurde die Diffusion von Wasserstoff in α-Palladium bei Raumtemperatur untersucht. Bei verschiedenen Strömen und Probendicken wurden einfache und mehrfache Wasserstoffbeladungsexperimente durchgeführt. Aus der allgemeinen Lösung für die Diffusion wird die mathematische Beschreibung der Mehrfachbeladung für diese galvanostatische Methode entwickelt. Der Diffusionskoeffizient bei 23 C wurde für Wasserstoff in α-Palladium zu (3,4 ± 0,2) × 10−7cm2/s bestimmt, in ausgezeichneter Übereinstimmung mit den Ergebnissen aus den Messungen des Gorsky-Effektes. Die Ergebnisse zeigen, daβ die Wasserstoffdiffusion im Volumen der geschwindigkeitsbestimmende Prozess ist; die in der mathematischen Analyse für den Wasserstoff-Fluβ angenommenen Randbedingungen werden durch die galvanostatische Methode erfüllt.}
}
@article{KHURANA199857,
title = {Towards holistic “front ends” in new product development},
journal = {Journal of Product Innovation Management},
volume = {15},
number = {1},
pages = {57-74},
year = {1998},
note = {The Third International Product Development Management Conference on New Approaches to Development and Engineering},
issn = {0737-6782},
doi = {https://doi.org/10.1016/S0737-6782(97)00066-0},
url = {https://www.sciencedirect.com/science/article/pii/S0737678297000660},
author = {Anil Khurana and Stephen R. Rosenthal},
abstract = {Any firm that hopes to compete on the basis of innovation clearly must be proficient in all phases of the new-product development (NPD) process. However, the real keys to success can be found in the activities that occur before management makes the go/no-go decision for any NPD project. In other words, the most significant benefits can be achieved through improvements in the performance of the front-end activities—product strategy formulation and communication, opportunity identification and assessment, idea generation, product definition, project planning, and executive reviews. Noting the inherent difficulty of managing the front end, Anil Khurana and Stephen R. Rosenthal discuss findings from in-depth case studies of the front-end practices in 18 business units from 12 U.S. and Japanese companies. They offer a process view of the activities that the front end comprises, and they discuss the insights that their case studies provide regarding key success factors for managing the front-end activities. The case studies involved companies in industries ranging from consumer packaged goods to electronics and industrial products. Foremost among the insights provided by the case studies is the notion that the greatest success comes to organizations that take a holistic approach to the front end. A successful approach to the front end effectively links business strategy, product strategy, and product-specific decisions. Forging these links requires a process that integrates such elements as product strategy, development portfolio, concept development, overall business justification, resource planning, core team roles, executive reviews, and decision mechanisms. The case studies suggest that firms employ two general approaches for achieving these links. Some companies rely on a formal process to lend some order and predictability to the front end. Other companies strive to foster a company-wide culture in which the key participants in front-end activities always remain focused on the following considerations: business vision, technical feasibility, customer focus, schedule, resources, and coordination. This cultural approach is more prevalent among the Japanese firms in the study; the U.S. firms tend to rely on formality of the front-end process. The case studies also suggest that the front-end approach must be compatible with the firm's product, market, and organizational contexts. For example, standardized approaches seem to work best for incremental innovations.}
}
@article{HAUSCHILD20051,
title = {From Life Cycle Assessment to Sustainable Production: Status and Perspectives},
journal = {CIRP Annals},
volume = {54},
number = {2},
pages = {1-21},
year = {2005},
issn = {0007-8506},
doi = {https://doi.org/10.1016/S0007-8506(07)60017-1},
url = {https://www.sciencedirect.com/science/article/pii/S0007850607600171},
author = {M. Hauschild and J. Jeswiet and L. Alting},
keywords = {Lifecycle, Sustainable production, Eco-design, Integrated Product Policy},
abstract = {The paper reviews the current state of Life Cycle Assessment (LCA) introducing the central elements of the methodology and the latest developments in assessment of the environmental, economic and social impacts along the product chain. The central role of LCA in Integrated Product Policy (IPP) is substantiated describing the different tools of the IPP. An overview is given on Design for Environment (DFE), presenting central findings from the latest decade of research and reviewing different DFE tools which have been developed. Describing the DFX's of Design for environment, a specific focus is devoted to the tools for design for disassembly. Life Cycle Engineering is defined, and a systematic hierarchy is presented for the different levels at which environmental impacts from industry can be addressed by the engineer in order to improve the eco-efficiency of the industry. The role of industry in meeting the sustainability challenge to our societies is discussed, and it is concluded that industry must include not only the eco-efficiency but also the product's environmental justification and the company ethics in a life cycle perspective in order to become sustainable. In the outlook it is concluded that current drivers seem insufficient to create a strong move of particularly the small and medium-sized enterprises in the direction of sustainability, and a need for stronger legislation and for education and attitude building among future citizens and engineers is identified.}
}